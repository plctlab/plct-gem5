def template VMemMacroDeclare {{

class %(class_name)s : public %(base_class)s
{
private:
    %(reg_idx_arr_decl)s;
public:
    %(class_name)s(ExtMachInst _machInst);
    using %(base_class)s::generateDisassembly;
};

}};

def template VMemTemplateMacroDeclare {{

template<typename ElemType>
class %(class_name)s : public %(base_class)s
{
private:
    %(reg_idx_arr_decl)s;
public:
    %(class_name)s(ExtMachInst _machInst);
    using %(base_class)s::generateDisassembly;
};

}};

def template VleConstructor {{

%(class_name)s::%(class_name)s(ExtMachInst _machInst)
    : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s)
{
    %(set_reg_idx_arr)s;
    %(constructor)s;

    const int32_t micro_vlmax = VLEN / width_EEW(_machInst.width);
    const uint32_t num_microops = ceil((float) this->vl / (micro_vlmax));
    int32_t remaining_vl = this->vl;
    int32_t micro_vl = std::min(remaining_vl, micro_vlmax);
    StaticInstPtr microop;

    if (micro_vl == 0) {
        microop = new VectorNopMicroInst(_machInst);
        this->microops.push_back(microop);
    }
    for (int i = 0; i < num_microops && micro_vl > 0; ++i) {
        microop = new %(class_name)sMicro(_machInst, micro_vl, i);
        microop->setDelayedCommit();
        microop->setFlag(IsLoad);
        this->microops.push_back(microop);
        micro_vl = std::min(remaining_vl -= micro_vlmax, micro_vlmax);
    }

    this->microops.front()->setFirstMicroop();
    this->microops.back()->setLastMicroop();
}

}};

def template VleMicroDeclare {{

class %(class_name)s : public %(base_class)s
{
private:
    RegId srcRegIdxArr[3];
    RegId destRegIdxArr[1];
public:
    %(class_name)s(ExtMachInst _machInst, uint8_t _microVl, uint8_t _microIdx)
    : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s, _microVl,
                     _microIdx)
    {
        %(set_reg_idx_arr)s;
        _numSrcRegs = 0;
        _numDestRegs = 0;
        setDestRegIdx(_numDestRegs++, vecRegClass[_machInst.vd + _microIdx]);
        _numTypedDestRegs[VecRegClass]++;
        setSrcRegIdx(_numSrcRegs++, intRegClass[_machInst.rs1]);
        setSrcRegIdx(_numSrcRegs++, vecRegClass[_machInst.vd + _microIdx]);
        if (!_machInst.vm) {
            setSrcRegIdx(_numSrcRegs++, vecRegClass[0]);
        }
    }

    Fault execute(ExecContext *, Trace::InstRecord *) const override;
    Fault initiateAcc(ExecContext *, Trace::InstRecord *) const override;
    Fault completeAcc(PacketPtr, ExecContext *,
                      Trace::InstRecord *) const override;
    using %(base_class)s::generateDisassembly;

};

}};

def template VleMicroExecute {{

Fault
%(class_name)s::execute(ExecContext *xc, Trace::InstRecord *traceData) const
{
    Addr EA;
    %(op_decl)s;
    %(op_rd)s;
    %(ea_code)s;

    RiscvISA::vreg_t tmp_v0;
    uint8_t *v0;
    if(!machInst.vm) {
        xc->getRegOperand(this, _numSrcRegs - 1, &tmp_v0);
        v0 = tmp_v0.as<uint8_t>();
    }

    uint32_t mem_size = width_EEW(machInst.width) / 8 * this->microVl;
    const std::vector<bool> byte_enable(mem_size, true);
    Fault fault = xc->readMem(EA, Mem.as<uint8_t>(), mem_size, memAccessFlags,
                              byte_enable);
    if (fault != NoFault)
        return fault;

    const size_t micro_vlmax = vtype_VLMAX(machInst.vtype8, true);
    const size_t micro_elems = VLEN / width_EEW(machInst.width);
    size_t ei;
    for (size_t i = 0; i < micro_elems; i++) {
        ei = i + micro_vlmax * microIdx;
        %(memacc_code)s;
    }

    %(op_wb)s;
    return fault;
}

}};

def template VleMicroInitiateAcc {{

Fault
%(class_name)s::initiateAcc(ExecContext* xc,
                            Trace::InstRecord* traceData) const
{
    Addr EA;

    %(op_src_decl)s;
    %(op_rd)s;
    %(ea_code)s;

    uint32_t mem_size = width_EEW(this->machInst.width) / 8 * this->microVl;
    const std::vector<bool> byte_enable(mem_size, true);
    Fault fault = initiateMemRead(xc, EA, mem_size, memAccessFlags,
                                  byte_enable);
    return fault;
}

}};

def template VleMicroCompleteAcc {{

Fault
%(class_name)s::completeAcc(PacketPtr pkt, ExecContext *xc,
                            Trace::InstRecord *traceData) const
{
    %(op_decl)s;
    %(op_rd)s;

    RiscvISA::vreg_t tmp_v0;
    uint8_t *v0;
    if(!machInst.vm) {
        xc->getRegOperand(this, _numSrcRegs - 1, &tmp_v0);
        v0 = tmp_v0.as<uint8_t>();
    }

    memcpy(Mem.as<uint8_t>(), pkt->getPtr<uint8_t>(), pkt->getSize());

    const size_t micro_vlmax = vtype_VLMAX(machInst.vtype8, true);
    const size_t micro_elems = VLEN / width_EEW(machInst.width);
    size_t ei;
    for (size_t i = 0; i < micro_elems; i++) {
        ei = i + micro_vlmax * microIdx;
        %(memacc_code)s;
    }

    %(op_wb)s;
    return NoFault;
}

}};

def template VseConstructor {{

%(class_name)s::%(class_name)s(ExtMachInst _machInst)
    : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s)
{
    %(set_reg_idx_arr)s;
    %(constructor)s;

    const int32_t micro_vlmax = VLEN / width_EEW(_machInst.width);
    const uint32_t num_microops = ceil((float) this->vl / (micro_vlmax));
    int32_t remaining_vl = this->vl;
    int32_t micro_vl = std::min(remaining_vl, micro_vlmax);

    StaticInstPtr microop;

    if (micro_vl == 0) {
        microop = new VectorNopMicroInst(_machInst);
        this->microops.push_back(microop);
    }
    for (int i = 0; i < num_microops && micro_vl > 0; ++i) {
        microop = new %(class_name)sMicro(_machInst, micro_vl, i);
        microop->setDelayedCommit();
        microop->setFlag(IsStore);
        this->microops.push_back(microop);
        micro_vl = std::min(remaining_vl -= micro_vlmax, micro_vlmax);
    }

    this->microops.front()->setFlag(IsFirstMicroop);
    this->microops.back()->setFlag(IsLastMicroop);
}

}};

def template VseMicroDeclare {{

class %(class_name)s : public %(base_class)s
{
private:
    RegId srcRegIdxArr[3];
    RegId destRegIdxArr[0];
public:
    %(class_name)s(ExtMachInst _machInst, uint8_t _microVl, uint8_t _microIdx)
        : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s,
                         _microVl, _microIdx)
    {
        %(set_reg_idx_arr)s;
        _numSrcRegs = 0;
        _numDestRegs = 0;
        setSrcRegIdx(_numSrcRegs++, intRegClass[_machInst.rs1]);
        setSrcRegIdx(_numSrcRegs++, vecRegClass[_machInst.vs3 + _microIdx]);
        if (!_machInst.vm) {
            setSrcRegIdx(_numSrcRegs++, vecRegClass[0]);
        }
        this->flags[IsVector] = true;
        this->flags[IsStore] = true;
    }

    Fault execute(ExecContext *, Trace::InstRecord *) const override;
    Fault initiateAcc(ExecContext *, Trace::InstRecord *) const override;
    Fault completeAcc(PacketPtr, ExecContext *,
                      Trace::InstRecord *) const override;
    using %(base_class)s::generateDisassembly;
};

}};

def template VseMicroExecute {{

Fault
%(class_name)s::execute(ExecContext *xc, Trace::InstRecord *traceData) const
{
    Addr EA;

    RiscvISA::vreg_t tmp_v0;
    uint8_t *v0;
    if(!machInst.vm) {
        xc->getRegOperand(this, _numSrcRegs - 1, &tmp_v0);
        v0 = tmp_v0.as<uint8_t>();
    }

    %(op_decl)s;
    %(op_rd)s;
    %(ea_code)s;

    const size_t micro_vlmax = vtype_VLMAX(machInst.vtype8, true);
    const size_t eewb = width_EEW(machInst.width) / 8;
    const size_t mem_size = eewb * microVl;
    std::vector<bool> byte_enable(mem_size, false);
    size_t ei;
    for (size_t i = 0; i < microVl; i++) {
        ei = i + micro_vlmax * microIdx;
        if (machInst.vm || elem_mask(v0, ei)) {
            %(memacc_code)s;
            auto it = byte_enable.begin() + i * eewb;
            std::fill(it, it + eewb, true);
        }
    }

    Fault fault;
    fault = xc->writeMem(Mem.as<uint8_t>(), mem_size, EA, memAccessFlags,
                         nullptr, byte_enable);
    return fault;
}

}};

def template VseMicroInitiateAcc {{

Fault
%(class_name)s::initiateAcc(ExecContext* xc,
                            Trace::InstRecord* traceData) const
{
    Addr EA;

    RiscvISA::vreg_t tmp_v0;
    uint8_t *v0;
    if(!machInst.vm) {
        xc->getRegOperand(this, _numSrcRegs - 1, &tmp_v0);
        v0 = tmp_v0.as<uint8_t>();
    }

    %(op_decl)s;
    %(op_rd)s;
    %(ea_code)s;

    const size_t micro_vlmax = vtype_VLMAX(machInst.vtype8, true);
    const size_t eewb = width_EEW(machInst.width) / 8;
    const size_t mem_size = eewb * microVl;
    std::vector<bool> byte_enable(mem_size, false);
    size_t ei;
    for (size_t i = 0; i < microVl; i++) {
        ei = i + micro_vlmax * microIdx;
        if (machInst.vm || elem_mask(v0, ei)) {
            %(memacc_code)s;
            auto it = byte_enable.begin() + i * eewb;
            std::fill(it, it + eewb, true);
        }
    }

    Fault fault;
    fault = xc->writeMem(Mem.as<uint8_t>(), mem_size, EA, memAccessFlags,
                         nullptr, byte_enable);
    return fault;
}

}};

def template VseMicroCompleteAcc {{

Fault
%(class_name)s::completeAcc(PacketPtr pkt, ExecContext* xc,
                            Trace::InstRecord* traceData) const
{
    return NoFault;
}

}};

def template VlmConstructor {{

%(class_name)s::%(class_name)s(ExtMachInst _machInst)
    : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s)
{
    %(set_reg_idx_arr)s;
    %(constructor)s;

    const uint32_t micro_vlmax = VLEN / width_EEW(_machInst.width);
    int32_t micro_vl = (std::min(this->vl, micro_vlmax) + 7) / 8;
    StaticInstPtr microop;

    if (micro_vl == 0) {
        microop = new VectorNopMicroInst(_machInst);
    } else {
        microop = new Vle8_vMicro(_machInst, micro_vl, 0);
        microop->setDelayedCommit();
        microop->setFlag(IsLoad);
    }
    this->microops.push_back(microop);

    this->microops.front()->setFirstMicroop();
    this->microops.back()->setLastMicroop();
}

}};

def template VsmConstructor {{

%(class_name)s::%(class_name)s(ExtMachInst _machInst)
    : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s)
{
    %(set_reg_idx_arr)s;
    %(constructor)s;

    const uint32_t micro_vlmax = VLEN / width_EEW(_machInst.width);
    int32_t micro_vl = (std::min(this->vl, micro_vlmax) + 7) / 8;

    StaticInstPtr microop;
    if (micro_vl == 0) {
        microop = new VectorNopMicroInst(_machInst);
    } else {
        microop = new Vse8_vMicro(_machInst, micro_vl, 0);
        microop->setDelayedCommit();
        microop->setFlag(IsStore);
    }
    this->microops.push_back(microop);

    this->microops.front()->setFirstMicroop();
    this->microops.back()->setLastMicroop();
}

}};

def template VsWholeConstructor {{

%(class_name)s::%(class_name)s(ExtMachInst _machInst)
  : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s)
{
    %(set_reg_idx_arr)s;
    %(constructor)s;

    size_t NFIELDS = machInst.nf + 1;
    const int32_t micro_vlmax = VLEN / width_EEW(_machInst.width);

    StaticInstPtr microop;
    for (int i = 0; i < NFIELDS; ++i) {
        microop = new %(class_name)sMicro(_machInst, micro_vlmax, i);
        microop->setDelayedCommit();
        microop->setFlag(IsStore);
        this->microops.push_back(microop);
    }

    this->microops.front()->setFirstMicroop();
    this->microops.back()->setLastMicroop();
}

}};

def template VsWholeMicroDeclare {{

class %(class_name)s: public %(base_class)s
{
private:
    RegId destRegIdxArr[0];
    RegId srcRegIdxArr[2];
public:
    %(class_name)s(ExtMachInst _machInst, uint8_t _microVl, uint8_t _microIdx)
        : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s,
                         _microVl, _microIdx)
    {
        %(set_reg_idx_arr)s;
        _numSrcRegs = 0;
        _numDestRegs = 0;
        setSrcRegIdx(_numSrcRegs++, intRegClass[_machInst.rs1]);
        setSrcRegIdx(_numSrcRegs++, vecRegClass[_machInst.vs3 + _microIdx]);
        this->flags[IsVector] = true;
        this->flags[IsStore] = true;
    }
    Fault execute(ExecContext *, Trace::InstRecord *) const override;
    Fault initiateAcc(ExecContext *, Trace::InstRecord *) const override;
    Fault completeAcc(PacketPtr, ExecContext *,
                        Trace::InstRecord *) const override;
    using %(base_class)s::generateDisassembly;
};

}};

def template VsWholeMicroExecute {{

Fault
%(class_name)s::execute(ExecContext *xc, Trace::InstRecord *traceData) const
{
    Addr EA;
    %(op_decl)s;
    %(op_rd)s;
    %(ea_code)s;

    for (size_t i = 0; i < VLENB; i++) {
        %(memacc_code)s;
    }

    Fault fault = writeMemAtomicLE(xc, traceData, *(vreg_t::Container*)(&Mem),
                                   EA, memAccessFlags, nullptr);
    return fault;
}

}};

def template VsWholeMicroInitiateAcc {{

Fault
%(class_name)s::initiateAcc(ExecContext* xc,
        Trace::InstRecord* traceData) const
{
    Addr EA;
    %(op_decl)s;
    %(op_rd)s;
    %(ea_code)s;

    for (size_t i = 0; i < VLENB; i++) {
        %(memacc_code)s;
    }

    Fault fault = writeMemTimingLE(xc, traceData, *(vreg_t::Container*)(&Mem),
                                   EA, memAccessFlags, nullptr);
    return fault;
}

}};

def template VsWholeMicroCompleteAcc {{

Fault
%(class_name)s::completeAcc(PacketPtr pkt, ExecContext* xc,
                            Trace::InstRecord* traceData) const
{
    return NoFault;
}

}};

def template VlWholeConstructor {{

%(class_name)s::%(class_name)s(ExtMachInst _machInst)
    : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s)
{
    %(set_reg_idx_arr)s;
    %(constructor)s;

    size_t NFIELDS = machInst.nf + 1;
    const int32_t micro_vlmax = VLEN / width_EEW(_machInst.width);

    StaticInstPtr microop;
    for (int i = 0; i < NFIELDS; ++i) {
        microop = new %(class_name)sMicro(_machInst, micro_vlmax, i);
        microop->setDelayedCommit();
        microop->setFlag(IsLoad);
        this->microops.push_back(microop);
    }

    this->microops.front()->setFirstMicroop();
    this->microops.back()->setLastMicroop();
}

}};

def template VlWholeMicroDeclare {{

class %(class_name)s: public %(base_class)s
{
private:
    RegId destRegIdxArr[1];
    RegId srcRegIdxArr[1];
public:
    %(class_name)s(ExtMachInst _machInst, uint8_t _microVl, uint8_t _microIdx)
        : %(base_class)s("%(mnemonic)s_micro", _machInst, %(op_class)s,
                         _microVl, _microIdx)
    {
        %(set_reg_idx_arr)s;
        _numSrcRegs = 0;
        _numDestRegs = 0;
        setDestRegIdx(_numDestRegs++, vecRegClass[_machInst.vd + _microIdx]);
        _numTypedDestRegs[VecRegClass]++;
        setSrcRegIdx(_numSrcRegs++, intRegClass[_machInst.rs1]);
        this->flags[IsVector] = true;
        this->flags[IsLoad] = true;
    }
    Fault execute(ExecContext *, Trace::InstRecord *) const override;
    Fault initiateAcc(ExecContext *, Trace::InstRecord *) const override;
    Fault completeAcc(PacketPtr, ExecContext *,
                        Trace::InstRecord *) const override;
    using %(base_class)s::generateDisassembly;
};

}};

def template VlWholeMicroExecute {{

Fault
%(class_name)s::execute(ExecContext *xc, Trace::InstRecord *traceData) const
{
    Addr EA;
    %(op_decl)s;
    %(op_rd)s;
    %(ea_code)s;

    Fault fault = readMemAtomicLE(xc, traceData, EA,
                                  *(vreg_t::Container*)(&Mem), memAccessFlags);
    if (fault != NoFault)
        return fault;

    size_t elem_per_reg = VLEN / width_EEW(machInst.width);
    for (size_t i = 0; i < elem_per_reg; i++) {
        %(memacc_code)s;
    }

    %(op_wb)s;
    return NoFault;
}

}};

def template VlWholeMicroInitiateAcc {{

Fault
%(class_name)s::initiateAcc(ExecContext* xc,
                            Trace::InstRecord* traceData) const
{
    Addr EA;
    %(op_src_decl)s;
    %(op_rd)s;
    %(ea_code)s;

    Fault fault = initiateMemRead(xc, traceData, EA, Mem, memAccessFlags);
    return fault;
}

}};

def template VlWholeMicroCompleteAcc {{

Fault
%(class_name)s::completeAcc(PacketPtr pkt, ExecContext* xc,
        Trace::InstRecord* traceData) const
{
    %(op_decl)s;
    %(op_rd)s;

    memcpy(Mem.as<uint8_t>(), pkt->getPtr<uint8_t>(), pkt->getSize());

    size_t elem_per_reg = VLEN / width_EEW(machInst.width);
    for (size_t i = 0; i < elem_per_reg; ++i) {
        %(memacc_code)s;
    }

    %(op_wb)s;
    return NoFault;
}

}};

def template VlStrideConstructor {{

%(class_name)s::%(class_name)s(ExtMachInst _machInst)
    : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s)
{
    %(set_reg_idx_arr)s;
    %(constructor)s;

    const int32_t num_elems_per_vreg = VLEN / width_EEW(_machInst.width);
    int32_t remaining_vl = this->vl;
    // Num of elems in one vreg
    int32_t micro_vl = std::min(remaining_vl, num_elems_per_vreg);
    StaticInstPtr microop;

    if (micro_vl == 0) {
        microop = new VectorNopMicroInst(_machInst);
        this->microops.push_back(microop);
    }
    for (int i = 0; micro_vl > 0; ++i) {
        for (int j = 0; j < micro_vl; ++j) {
            microop = new %(class_name)sMicro(machInst, i, j, micro_vl);
            microop->setFlag(IsDelayedCommit);
            microop->setFlag(IsLoad);
            this->microops.push_back(microop);
        }
        remaining_vl -= num_elems_per_vreg;
        micro_vl = std::min(remaining_vl, num_elems_per_vreg);
    }

    this->microops.front()->setFlag(IsFirstMicroop);
    this->microops.back()->setFlag(IsLastMicroop);
    this->flags[IsVector] = true;
}

}};

def template VlStrideMicroDeclare {{

class %(class_name)s : public %(base_class)s
{
private:
    // rs1, rs2, vd, vm
    RegId srcRegIdxArr[4];
    RegId destRegIdxArr[1];
public:
    %(class_name)s(ExtMachInst _machInst, uint8_t _regIdx, uint8_t _microIdx,
        uint8_t _microVl)
    : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s,
        _regIdx, _microIdx, _microVl)
    {
        %(set_reg_idx_arr)s;
        _numSrcRegs = 0;
        _numDestRegs = 0;
        setDestRegIdx(_numDestRegs++, vecRegClass[_machInst.vd + _regIdx]);
        _numTypedDestRegs[VecRegClass]++;
        setSrcRegIdx(_numSrcRegs++, intRegClass[_machInst.rs1]);
        setSrcRegIdx(_numSrcRegs++, intRegClass[_machInst.rs2]);
        // We treat agnostic as undistrubed
        setSrcRegIdx(_numSrcRegs++, vecRegClass[_machInst.vd + _regIdx]);
        if (!_machInst.vm) {
            setSrcRegIdx(_numSrcRegs++, vecRegClass[0]);
        }
        this->flags[IsLoad] = true;
    }

    Fault execute(ExecContext *, Trace::InstRecord *) const override;
    Fault initiateAcc(ExecContext *, Trace::InstRecord *) const override;
    Fault completeAcc(PacketPtr, ExecContext *,
                      Trace::InstRecord *) const override;
    using %(base_class)s::generateDisassembly;
};

}};

def template VlStrideMicroExecute {{

Fault
%(class_name)s::execute(ExecContext *xc, Trace::InstRecord *traceData) const
{
    Fault fault = NoFault;
    Addr EA;

    %(op_decl)s;
    %(op_rd)s;
    constexpr uint8_t elem_size = sizeof(Vd[0]);
    %(ea_code)s; // ea_code depends on elem_size

    RiscvISA::vreg_t tmp_v0;
    uint8_t *v0;
    if (!machInst.vm) {
        xc->getRegOperand(this, _numSrcRegs-1, &tmp_v0);
        v0 = tmp_v0.as<uint8_t>();
    }

    uint32_t mem_size = elem_size;
    const std::vector<bool> byte_enable(mem_size, true);

    size_t ei = this->regIdx * VLENB / elem_size + this->microIdx;
    if (machInst.vm || elem_mask(v0, ei)) {
        fault = xc->readMem(EA, Mem.as<uint8_t>(), mem_size,
                                memAccessFlags, byte_enable);
        if (fault != NoFault)
            return fault;
        %(memacc_code)s; /* Vd[this->microIdx] = Mem[0]; */
    }

    %(op_wb)s;
    return fault;
}

}};

def template VlStrideMicroInitiateAcc {{

Fault
%(class_name)s::initiateAcc(ExecContext* xc,
                            Trace::InstRecord* traceData) const
{
    Fault fault = NoFault;
    Addr EA;

    %(op_src_decl)s;
    %(op_rd)s;
    constexpr uint8_t elem_size = sizeof(Vd[0]);
    %(ea_code)s; // ea_code depends on elem_size

    RiscvISA::vreg_t tmp_v0;
    uint8_t *v0;
    if (!machInst.vm) {
        xc->getRegOperand(this, _numSrcRegs-1, &tmp_v0);
        v0 = tmp_v0.as<uint8_t>();
    }

    uint32_t mem_size = elem_size;
    size_t ei = this->regIdx * VLENB / elem_size + this->microIdx;
    bool need_load = machInst.vm || elem_mask(v0, ei);
    const std::vector<bool> byte_enable(mem_size, need_load);
    fault = initiateMemRead(xc, EA, mem_size, memAccessFlags, byte_enable);
    return fault;
}

}};

def template VlStrideMicroCompleteAcc {{

Fault
%(class_name)s::completeAcc(PacketPtr pkt, ExecContext *xc,
                            Trace::InstRecord *traceData) const
{
    %(op_decl)s;
    %(op_rd)s;

    constexpr uint8_t elem_size = sizeof(Vd[0]);

    RiscvISA::vreg_t old_vd;
    decltype(Vd) old_Vd = nullptr;
    // We treat agnostic as undistrubed
    xc->getRegOperand(this, 2, &old_vd);
    old_Vd = old_vd.as<std::remove_reference_t<decltype(Vd[0])> >();

    RiscvISA::vreg_t tmp_v0;
    uint8_t *v0;
    if (!machInst.vm) {
        xc->getRegOperand(this, _numSrcRegs-1, &tmp_v0);
        v0 = tmp_v0.as<uint8_t>();
    }

    if (microIdx == 0) {
        // treat vma as vmu
        // if (machInst.vtype8.vma == 0)
        memcpy(Vd, old_Vd, microVl * elem_size);
        // treat vta as vtu
        // if (machInst.vtype8.vta == 0)
        memcpy(Vd + microVl, old_Vd + microVl, VLENB - microVl * elem_size);
    } else {
        memcpy(Vd, old_Vd, VLENB);
    }

    size_t ei = this->regIdx * VLENB / sizeof(Vd[0]) + this->microIdx;
    if (machInst.vm || elem_mask(v0, ei)) {
        memcpy(Mem.as<uint8_t>(), pkt->getPtr<uint8_t>(), pkt->getSize());
        %(memacc_code)s; /* Vd[this->microIdx] = Mem[0]; */
    }

    %(op_wb)s;
    return NoFault;
}

}};

def template VsStrideConstructor {{

%(class_name)s::%(class_name)s(ExtMachInst _machInst)
    : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s)
{
    %(set_reg_idx_arr)s;
    %(constructor)s;

    const int32_t num_elems_per_vreg = VLEN / width_EEW(_machInst.width);
    int32_t remaining_vl = this->vl;
    // Num of elems in one vreg
    int32_t micro_vl = std::min(remaining_vl, num_elems_per_vreg);
    StaticInstPtr microop;

    if (micro_vl == 0) {
        microop = new VectorNopMicroInst(_machInst);
        this->microops.push_back(microop);
    }
    for (int i = 0; micro_vl > 0; ++i) {
        for (int j = 0; j < micro_vl; ++j) {
            microop = new %(class_name)sMicro(machInst, i, j, micro_vl);
            microop->setFlag(IsDelayedCommit);
            microop->setFlag(IsStore);
            this->microops.push_back(microop);
        }
        remaining_vl -= num_elems_per_vreg;
        micro_vl = std::min(remaining_vl, num_elems_per_vreg);
    }

    this->microops.front()->setFlag(IsFirstMicroop);
    this->microops.back()->setFlag(IsLastMicroop);
    this->flags[IsVector] = true;
}

}};

def template VsStrideMicroDeclare {{

class %(class_name)s : public %(base_class)s
{
private:
    // rs1, rs2, vs3, vm
    RegId srcRegIdxArr[4];
    RegId destRegIdxArr[0];
public:
    %(class_name)s(ExtMachInst _machInst, uint8_t _regIdx, uint8_t _microIdx,
            uint8_t _microVl)
        : %(base_class)s("%(mnemonic)s""_micro", _machInst, %(op_class)s,
            _regIdx, _microIdx, _microVl)
    {
        %(set_reg_idx_arr)s;
        _numSrcRegs = 0;
        _numDestRegs = 0;
        setSrcRegIdx(_numSrcRegs++, intRegClass[_machInst.rs1]);
        setSrcRegIdx(_numSrcRegs++, intRegClass[_machInst.rs2]);
        setSrcRegIdx(_numSrcRegs++, vecRegClass[_machInst.vs3 + _regIdx]);
        if (!_machInst.vm) {
            setSrcRegIdx(_numSrcRegs++, vecRegClass[0]);
        }
        this->flags[IsStore] = true;
    }

    Fault execute(ExecContext *, Trace::InstRecord *) const override;
    Fault initiateAcc(ExecContext *, Trace::InstRecord *) const override;
    Fault completeAcc(PacketPtr, ExecContext *,
                      Trace::InstRecord *) const override;
    using %(base_class)s::generateDisassembly;
};

}};

def template VsStrideMicroExecute {{

Fault
%(class_name)s::execute(ExecContext *xc, Trace::InstRecord *traceData) const
{
    Fault fault = NoFault;
    Addr EA;

    %(op_decl)s;
    %(op_rd)s;
    constexpr uint8_t elem_size = sizeof(Vs3[0]);
    %(ea_code)s;

    RiscvISA::vreg_t tmp_v0;
    uint8_t *v0;
    if(!machInst.vm) {
        xc->getRegOperand(this, _numSrcRegs - 1, &tmp_v0);
        v0 = tmp_v0.as<uint8_t>();
    }

    uint32_t mem_size = elem_size;
    const std::vector<bool> byte_enable(mem_size, true);

    size_t ei = this->regIdx * VLENB / elem_size + this->microIdx;
    if (machInst.vm || elem_mask(v0, ei)) {
        %(memacc_code)s;
        fault = xc->writeMem(Mem.as<uint8_t>(), mem_size, EA,
                             memAccessFlags, nullptr, byte_enable);
    }
    return fault;
}

}};

def template VsStrideMicroInitiateAcc {{

Fault
%(class_name)s::initiateAcc(ExecContext* xc,
                            Trace::InstRecord* traceData) const
{
    Fault fault = NoFault;
    Addr EA;

    RiscvISA::vreg_t tmp_v0;
    uint8_t *v0;
    if(!machInst.vm) {
        xc->getRegOperand(this, _numSrcRegs - 1, &tmp_v0);
        v0 = tmp_v0.as<uint8_t>();
    }

    %(op_decl)s;
    %(op_rd)s;
    constexpr uint8_t elem_size = sizeof(Vs3[0]);
    %(ea_code)s;

    uint32_t mem_size = elem_size;
    size_t ei = this->regIdx * VLENB / elem_size + this->microIdx;
    bool need_store = machInst.vm || elem_mask(v0, ei);
    if (need_store) {
        const std::vector<bool> byte_enable(mem_size, need_store);
        %(memacc_code)s;
        fault = xc->writeMem(Mem.as<uint8_t>(), mem_size, EA,
                            memAccessFlags, nullptr, byte_enable);
    }
    return fault;
}

}};

def template VsStrideMicroCompleteAcc {{

Fault
%(class_name)s::completeAcc(PacketPtr pkt, ExecContext* xc,
                            Trace::InstRecord* traceData) const
{
    return NoFault;
}

}};

def template VlIndexConstructor {{

template<typename ElemType>
%(class_name)s<ElemType>::%(class_name)s(ExtMachInst _machInst)
    : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s)
{
    %(set_reg_idx_arr)s;
    %(constructor)s;

    const uint32_t vd_eewb = sizeof(ElemType);
    const uint32_t vs2_eewb = width_EEW(_machInst.width) / 8;
    const uint8_t vs2_split_num = (vd_eewb + vs2_eewb - 1) / vs2_eewb;
    const uint8_t vd_split_num = (vs2_eewb + vd_eewb - 1) / vd_eewb;
    const int32_t micro_vlmax = VLENB / std::max(vd_eewb, vs2_eewb);
    int32_t remaining_vl = this->vl;
    int32_t micro_vl = std::min(remaining_vl, micro_vlmax);
    StaticInstPtr microop;

    if (micro_vl == 0) {
        microop = new VectorNopMicroInst(_machInst);
        this->microops.push_back(microop);
    }
    for (uint8_t i = 0; micro_vl > 0; i++) {
        for (uint8_t j = 0; j < micro_vl; ++j) {
            uint8_t vdRegIdx = i / vd_split_num;
            uint8_t vs2RegIdx = i / vs2_split_num;
            uint8_t vdElemIdx = j + micro_vlmax * (i % vd_split_num);
            uint8_t vs2ElemIdx = j + micro_vlmax * (i % vs2_split_num);
            microop = new %(class_name)sMicro<ElemType>(machInst,
                vdRegIdx, vdElemIdx, vs2RegIdx, vs2ElemIdx);
            microop->setFlag(IsDelayedCommit);
            microop->setFlag(IsLoad);
            this->microops.push_back(microop);
        }
        remaining_vl -= micro_vlmax;
        micro_vl = std::min(remaining_vl, micro_vlmax);
    }

    this->microops.front()->setFlag(IsFirstMicroop);
    this->microops.back()->setFlag(IsLastMicroop);
    this->flags[IsVector] = true;
}

}};

def template VlIndexMicroDeclare {{

template<typename ElemType>
class %(class_name)s : public %(base_class)s
{
private:
    // rs1, vs2, vd, vm
    RegId srcRegIdxArr[4];
    RegId destRegIdxArr[1];
public:
    %(class_name)s(ExtMachInst _machInst,
        uint8_t _vdRegIdx, uint8_t _vdElemIdx,
        uint8_t _vs2RegIdx, uint8_t _vs2ElemIdx)
    : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s,
        _vdRegIdx, _vdElemIdx, _vs2RegIdx, _vs2ElemIdx)
    {
        %(set_reg_idx_arr)s;
        _numSrcRegs = 0;
        _numDestRegs = 0;
        setDestRegIdx(_numDestRegs++, vecRegClass[_machInst.vd + _vdRegIdx]);
        _numTypedDestRegs[VecRegClass]++;
        setSrcRegIdx(_numSrcRegs++, intRegClass[_machInst.rs1]);
        setSrcRegIdx(_numSrcRegs++, vecRegClass[_machInst.vs2 + _vs2RegIdx]);
        // We treat agnostic as undistrubed
        setSrcRegIdx(_numSrcRegs++, vecRegClass[_machInst.vd + _vdRegIdx]);
        if (!_machInst.vm) {
            setSrcRegIdx(_numSrcRegs++, vecRegClass[0]);
        }
        this->flags[IsLoad] = true;
    }

    Fault execute(ExecContext *, Trace::InstRecord *) const override;
    Fault initiateAcc(ExecContext *, Trace::InstRecord *) const override;
    Fault completeAcc(PacketPtr, ExecContext *,
                      Trace::InstRecord *) const override;
    using %(base_class)s::generateDisassembly;
};

}};

def template VlIndexMicroExecute {{

template<typename ElemType>
Fault
%(class_name)s<ElemType>::execute(ExecContext *xc,
    Trace::InstRecord *traceData)const
{
    using vu = std::make_unsigned_t<ElemType>;
    Fault fault = NoFault;
    Addr EA;

    %(op_decl)s;
    %(op_rd)s;
    %(ea_code)s;
    constexpr uint8_t elem_size = sizeof(Vd[0]);
    RiscvISA::vreg_t tmp_v0;
    uint8_t *v0;
    if (!machInst.vm) {
        xc->getRegOperand(this, _numSrcRegs-1, &tmp_v0);
        v0 = tmp_v0.as<uint8_t>();
    }

    uint32_t mem_size = elem_size;
    const std::vector<bool> byte_enable(mem_size, true);

    size_t ei = this->vdRegIdx * VLENB / elem_size + this->vdElemIdx;
    if (machInst.vm || elem_mask(v0, ei)) {
        fault = xc->readMem(EA, Mem.as<uint8_t>(), mem_size,
                                memAccessFlags, byte_enable);
        if (fault != NoFault)
            return fault;
        %(memacc_code)s; /* Vd[this->vdElemIdx] = Mem[0]; */
    }

    %(op_wb)s;
    return fault;
}

}};

def template VlIndexMicroInitiateAcc {{

template<typename ElemType>
Fault
%(class_name)s<ElemType>::initiateAcc(ExecContext* xc,
                            Trace::InstRecord* traceData) const
{
    using vu = std::make_unsigned_t<ElemType>;
    Fault fault = NoFault;
    Addr EA;

    %(op_src_decl)s;
    %(op_rd)s;
    constexpr uint8_t elem_size = sizeof(Vd[0]);
    %(ea_code)s; // ea_code depends on elem_size

    RiscvISA::vreg_t tmp_v0;
    uint8_t *v0;
    if (!machInst.vm) {
        xc->getRegOperand(this, _numSrcRegs-1, &tmp_v0);
        v0 = tmp_v0.as<uint8_t>();
    }

    uint32_t mem_size = elem_size;
    size_t ei = this->vdRegIdx * VLENB / elem_size + this->vdElemIdx;
    bool need_load = machInst.vm || elem_mask(v0, ei);
    const std::vector<bool> byte_enable(mem_size, need_load);
    fault = initiateMemRead(xc, EA, mem_size, memAccessFlags, byte_enable);
    return fault;
}

}};

def template VlIndexMicroCompleteAcc {{

template<typename ElemType>
Fault
%(class_name)s<ElemType>::completeAcc(PacketPtr pkt, ExecContext *xc,
                            Trace::InstRecord *traceData) const
{
    using vu = std::make_unsigned_t<ElemType>;
    %(op_decl)s;
    %(op_rd)s;

    constexpr uint8_t elem_size = sizeof(Vd[0]);

    RiscvISA::vreg_t old_vd;
    decltype(Vd) old_Vd = nullptr;
    // We treat agnostic as undistrubed
    xc->getRegOperand(this, 2, &old_vd);
    old_Vd = old_vd.as<std::remove_reference_t<decltype(Vd[0])> >();

    RiscvISA::vreg_t tmp_v0;
    uint8_t *v0;
    if (!machInst.vm) {
        xc->getRegOperand(this, _numSrcRegs-1, &tmp_v0);
        v0 = tmp_v0.as<uint8_t>();
    }

    memcpy(Vd, old_Vd, VLENB);

    size_t ei = this->vdRegIdx * VLENB / elem_size + this->vdElemIdx;
    if (machInst.vm || elem_mask(v0, ei)) {
        memcpy(Mem.as<uint8_t>(), pkt->getPtr<uint8_t>(), pkt->getSize());
        %(memacc_code)s; /* Vd[this->microIdx] = Mem[0]; */
    }

    %(op_wb)s;
    return NoFault;
}

}};

def template VsIndexConstructor {{

template<typename ElemType>
%(class_name)s<ElemType>::%(class_name)s(ExtMachInst _machInst)
    : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s)
{
    %(set_reg_idx_arr)s;
    %(constructor)s;

    const uint32_t vs3_eewb = sizeof(ElemType);
    const uint32_t vs2_eewb = width_EEW(_machInst.width) / 8;
    const uint8_t vs2_split_num = (vs3_eewb + vs2_eewb - 1) / vs2_eewb;
    const uint8_t vs3_split_num = (vs2_eewb + vs3_eewb - 1) / vs3_eewb;
    const int32_t micro_vlmax = VLENB / std::max(vs3_eewb, vs2_eewb);
    int32_t remaining_vl = this->vl;
    int32_t micro_vl = std::min(remaining_vl, micro_vlmax);
    StaticInstPtr microop;

    if (micro_vl == 0) {
        microop = new VectorNopMicroInst(_machInst);
        this->microops.push_back(microop);
    }
    for (uint8_t i = 0; micro_vl > 0; i++) {
        for (uint8_t j = 0; j < micro_vl; ++j) {
            uint8_t vs3RegIdx = i / vs3_split_num;
            uint8_t vs2RegIdx = i / vs2_split_num;
            uint8_t vs3ElemIdx = j + micro_vlmax * (i % vs3_split_num);
            uint8_t vs2ElemIdx = j + micro_vlmax * (i % vs2_split_num);
            microop = new %(class_name)sMicro<ElemType>(machInst,
                vs3RegIdx, vs3ElemIdx, vs2RegIdx, vs2ElemIdx);
            microop->setFlag(IsDelayedCommit);
            microop->setFlag(IsStore);
            this->microops.push_back(microop);
        }
        remaining_vl -= micro_vlmax;
        micro_vl = std::min(remaining_vl, micro_vlmax);
    }

    this->microops.front()->setFlag(IsFirstMicroop);
    this->microops.back()->setFlag(IsLastMicroop);
    this->flags[IsVector] = true;
}

}};

def template VsIndexMicroDeclare {{

template<typename ElemType>
class %(class_name)s : public %(base_class)s
{
private:
    // rs1, vs2, vs3, vm
    RegId srcRegIdxArr[4];
    RegId destRegIdxArr[0];
public:
    %(class_name)s(ExtMachInst _machInst,
        uint8_t _vs3RegIdx, uint8_t _vs3ElemIdx,
        uint8_t _vs2RegIdx, uint8_t _vs2ElemIdx)
    : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s,
        _vs3RegIdx, _vs3ElemIdx, _vs2RegIdx, _vs2ElemIdx)
    {
        %(set_reg_idx_arr)s;
        _numSrcRegs = 0;
        _numDestRegs = 0;
        setSrcRegIdx(_numSrcRegs++, intRegClass[_machInst.rs1]);
        setSrcRegIdx(_numSrcRegs++, vecRegClass[_machInst.vs2 + _vs2RegIdx]);
        // We treat agnostic as undistrubed
        setSrcRegIdx(_numSrcRegs++, vecRegClass[_machInst.vs3 + _vs3RegIdx]);
        if (!_machInst.vm) {
            setSrcRegIdx(_numSrcRegs++, vecRegClass[0]);
        }
        this->flags[IsStore] = true;
    }

    Fault execute(ExecContext *, Trace::InstRecord *) const override;
    Fault initiateAcc(ExecContext *, Trace::InstRecord *) const override;
    Fault completeAcc(PacketPtr, ExecContext *,
                      Trace::InstRecord *) const override;
    using %(base_class)s::generateDisassembly;
};

}};

def template VsIndexMicroExecute {{

template<typename ElemType>
Fault
%(class_name)s<ElemType>::execute(ExecContext *xc,
    Trace::InstRecord *traceData)const
{
    using vu = std::make_unsigned_t<ElemType>;
    Fault fault = NoFault;
    Addr EA;

    %(op_decl)s;
    %(op_rd)s;
    %(ea_code)s;
    constexpr uint8_t elem_size = sizeof(Vs3[0]);
    RiscvISA::vreg_t tmp_v0;
    uint8_t *v0;
    if (!machInst.vm) {
        xc->getRegOperand(this, _numSrcRegs-1, &tmp_v0);
        v0 = tmp_v0.as<uint8_t>();
    }

    uint32_t mem_size = elem_size;
    const std::vector<bool> byte_enable(mem_size, true);

    size_t ei = this->vs3RegIdx * VLENB / elem_size + this->vs3ElemIdx;
    if (machInst.vm || elem_mask(v0, ei)) {
        %(memacc_code)s; /* Mem[0] = Vs3[this->vs3ElemIdx] */
        fault = xc->writeMem(Mem.as<uint8_t>(), mem_size, EA,
                             memAccessFlags, nullptr, byte_enable);
    }
    return fault;
}

}};

def template VsIndexMicroInitiateAcc {{

template<typename ElemType>
Fault
%(class_name)s<ElemType>::initiateAcc(ExecContext* xc,
                            Trace::InstRecord* traceData) const
{
    using vu = std::make_unsigned_t<ElemType>;
    Fault fault = NoFault;
    Addr EA;

    %(op_src_decl)s;
    %(op_rd)s;
    %(ea_code)s;
    constexpr uint8_t elem_size = sizeof(Vs3[0]);
    RiscvISA::vreg_t tmp_v0;
    uint8_t *v0;
    if (!machInst.vm) {
        xc->getRegOperand(this, _numSrcRegs-1, &tmp_v0);
        v0 = tmp_v0.as<uint8_t>();
    }

    constexpr uint8_t mem_size = elem_size;
    const std::vector<bool> byte_enable(mem_size, true);

    size_t ei = this->vs3RegIdx * VLENB / elem_size + this->vs3ElemIdx;
    if (machInst.vm || elem_mask(v0, ei)) {
        %(memacc_code)s; /* Mem[0] = Vs3[this->vs3ElemIdx] */
        fault = xc->writeMem(Mem.as<uint8_t>(), mem_size, EA,
                             memAccessFlags, nullptr, byte_enable);
    }
    return fault;
}

}};

def template VsIndexMicroCompleteAcc {{

template<typename ElemType>
Fault
%(class_name)s<ElemType>::completeAcc(PacketPtr pkt, ExecContext* xc,
                            Trace::InstRecord* traceData) const
{
    return NoFault;
}

}};

def template VMemTemplateDecodeBlock {{

switch(machInst.vtype8.vsew) {
    case 0b000: {
        return new %(class_name)s<uint8_t>(machInst);
    }
    case 0b001: {
        return new %(class_name)s<uint16_t>(machInst);
    }
    case 0b010: {
        return new %(class_name)s<uint32_t>(machInst);
    }
    case 0b011: {
        return new %(class_name)s<uint64_t>(machInst);
    }
    default: GEM5_UNREACHABLE;
}

}};