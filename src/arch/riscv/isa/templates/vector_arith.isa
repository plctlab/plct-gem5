output header {{

#define ASSIGN_VD_BIT(idx, bit) \
    ((Vd[(idx)/8] & ~(1 << (idx)%8)) | ((bit) << (idx)%8))

#define COPY_OLD_VD(idx)                                             \
    [[maybe_unused]] RiscvISA::vreg_t old_vd;                        \
    [[maybe_unused]] decltype(Vd) old_Vd = nullptr;                  \
    xc->getRegOperand(this, (idx), &old_vd);                           \
    old_Vd = old_vd.as<std::remove_reference_t<decltype(Vd[0])> >(); \
    memcpy(Vd, old_Vd, VLENB);

#define VRM_REQUIRED                                                         \
        uint_fast8_t frm = xc->readMiscReg(MISCREG_FRM);                     \
        if (frm > 4)                                                         \
            return std::make_shared<IllegalInstFault>("RM fault", machInst); \
        softfloat_roundingMode = frm;

template<typename Type>
bool inline
carry_out(Type a, Type b, bool carry_in = false) {
    using TypeU = std::make_unsigned_t<Type>;
    TypeU s = *reinterpret_cast<TypeU*>(&a)
            + *reinterpret_cast<TypeU*>(&b) + carry_in;
    return carry_in
        ? (s <= *reinterpret_cast<TypeU*>(&a))
        : (s <  *reinterpret_cast<TypeU*>(&a));
}

template<typename Type>
bool inline
borrow_out(Type a, Type b, bool borrow_in = false) {
    using TypeU = std::make_unsigned_t<Type>;
    return borrow_in
        ? (*reinterpret_cast<TypeU*>(&a) <= *reinterpret_cast<TypeU*>(&b))
        : (*reinterpret_cast<TypeU*>(&a) <  *reinterpret_cast<TypeU*>(&b));
}

}};

def template VectorIntMacroDeclare {{

template<typename ElemType>
class %(class_name)s : public %(base_class)s {
private:
    %(reg_idx_arr_decl)s;
public:
    %(class_name)s(ExtMachInst _machInst);
    using %(base_class)s::generateDisassembly;
};

}};

def template VectorIntMacroConstructor {{

template<typename ElemType>
%(class_name)s<ElemType>::%(class_name)s(ExtMachInst _machInst)
    : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s)
{
    %(set_reg_idx_arr)s;
    %(constructor)s;
    const uint32_t num_microops = vtype_regs_per_group(vtype);
    int32_t tmp_vl = this->vl;
    const int32_t micro_vlmax = vtype_VLMAX(_machInst.vtype8, true);
    int32_t micro_vl = std::min(tmp_vl, micro_vlmax);
    StaticInstPtr microop;

    if (micro_vl == 0) {
        microop = new VectorNopMicroInst(_machInst);
        this->microops.push_back(microop);
    }
    for (int i = 0; i < num_microops && micro_vl > 0; ++i) {
        microop = new %(class_name)sMicro<ElemType>(_machInst, micro_vl, i);
        microop->setDelayedCommit();
        this->microops.push_back(microop);
        micro_vl = std::min(tmp_vl -= micro_vlmax, micro_vlmax);
    }

    this->microops.front()->setFirstMicroop();
    this->microops.back()->setLastMicroop();
}
}};

def template VectorIntMicroDeclare {{

template<typename ElemType>
class %(class_name)s : public %(base_class)s
{
private:
    // vs1, vs2, vs3(old_vd), vm for *.vv, *.vx
    // vs2, (old_vd), vm for *.vi
    RegId srcRegIdxArr[4];
    RegId destRegIdxArr[1];
    bool vm;
public:
    %(class_name)s(ExtMachInst _machInst, uint8_t _microVl,
                   uint8_t _microIdx);
    Fault execute(ExecContext* xc, trace::InstRecord* traceData)const override;
    using %(base_class)s::generateDisassembly;
};

}};

def template VectorIntMicroConstructor {{

template<typename ElemType>
%(class_name)s<ElemType>::%(class_name)s(ExtMachInst _machInst,
                                         uint8_t _microVl, uint8_t _microIdx)
    : %(base_class)s("%(mnemonic)s", _machInst,
                     %(op_class)s, _microVl, _microIdx)
{
    this->vm = _machInst.vm;
    %(set_reg_idx_arr)s;
    _numSrcRegs = 0;
    _numDestRegs = 0;
    %(set_dest_reg_idx)s;
    %(set_src_reg_idx)s;
}

}};

def template VectorIntMicroExecute {{

template <typename ElemType>
Fault
%(class_name)s<ElemType>::execute(ExecContext* xc,
                                  trace::InstRecord* traceData) const
{
    using vu [[maybe_unused]] = std::make_unsigned_t<ElemType>;
    using vi [[maybe_unused]] = std::make_signed_t<ElemType>;
    [[maybe_unused]] constexpr size_t sew = sizeof(vu) * 8;

    if (machInst.vill)
        return std::make_shared<IllegalInstFault>("VILL is set", machInst);

    %(op_decl)s;
    %(op_rd)s;
    %(vm_decl_rd)s;
    %(copy_old_vd)s;
    %(code)s;
    %(op_wb)s;

    return NoFault;
}

}};

def template VectorIntExtMacroDeclare {{

template<typename ElemType>
class %(class_name)s : public %(base_class)s {
private:
    %(reg_idx_arr_decl)s;
public:
    %(class_name)s(ExtMachInst _machInst);
    std::string generateDisassembly(Addr pc,
        const loader::SymbolTable *symtab) const override
    {
        std::stringstream ss;
        ss << mnemonic << ' ' << registerName(destRegIdx(0)) << ", "
            << registerName(srcRegIdx(0));
        if (machInst.vm == 0) ss << ", v0.t";
        return ss.str();
    }
};

}};

def template VectorIntExtMicroDeclare {{

template<typename ElemType>
class %(class_name)s : public %(base_class)s
{
private:
    RegId srcRegIdxArr[3];
    RegId destRegIdxArr[1];
    bool vm;
public:
    %(class_name)s(ExtMachInst _machInst, uint8_t _microVl,
                   uint8_t _microIdx);
    Fault execute(ExecContext* xc, trace::InstRecord* traceData)const override;
    std::string generateDisassembly(Addr pc,
        const loader::SymbolTable *symtab) const override
    {
        std::stringstream ss;
        ss << mnemonic << ' ' << registerName(destRegIdx(0)) << ", "
            << registerName(srcRegIdx(0));
        if (machInst.vm == 0) ss << ", v0.t";
        return ss.str();
    }
};

}};

def template VectorIntExtMicroExecute {{

template <typename ElemType>
Fault
%(class_name)s<ElemType>::execute(ExecContext* xc,
                                  trace::InstRecord* traceData) const
{
    using vu [[maybe_unused]] = std::make_unsigned_t<ElemType>;
    using vi [[maybe_unused]] = std::make_signed_t<ElemType>;

    if (machInst.vill)
        return std::make_shared<IllegalInstFault>("VILL is set", machInst);

    auto SEW = vtype_SEW(vtype);
    auto offset = (VLEN / SEW) * (microIdx % %(ext_div)d);
    switch (SEW / %(ext_div)d) {
      case 8: {
        using vext  [[maybe_unused]] = int8_t;
        using vextu [[maybe_unused]] = uint8_t;
        %(op_decl)s;
        %(op_rd)s;
        %(vm_decl_rd)s;
        %(copy_old_vd)s;
        %(code)s;
        %(op_wb)s;
        break;
      }
      case 16: {
        using vext  [[maybe_unused]] = int16_t;
        using vextu [[maybe_unused]] = uint16_t;
        %(op_decl)s;
        %(op_rd)s;
        %(vm_decl_rd)s;
        %(copy_old_vd)s;
        %(code)s;
        %(op_wb)s;
        break;
      }
      case 32: {
        using vext  [[maybe_unused]] = int32_t;
        using vextu [[maybe_unused]] = uint32_t;
        %(op_decl)s;
        %(op_rd)s;
        %(vm_decl_rd)s;
        %(copy_old_vd)s;
        %(code)s;
        %(op_wb)s;
      break;
      }
      default: break;
    }

    return NoFault;
}

}};

def template VectorIntDecodeBlock {{

switch(machInst.vtype8.vsew) {
case 0b000: return new %(class_name)s<uint8_t>(machInst);
case 0b001: return new %(class_name)s<uint16_t>(machInst);
case 0b010: return new %(class_name)s<uint32_t>(machInst);
case 0b011: return new %(class_name)s<uint64_t>(machInst);
default: GEM5_UNREACHABLE;
}

}};

def template VectorIntWideningMacroDeclare {{

template<typename ElemType>
class %(class_name)s : public %(base_class)s {
private:
    %(reg_idx_arr_decl)s;
public:
    %(class_name)s(ExtMachInst _machInst);
    using %(base_class)s::generateDisassembly;
};

}};

def template VectorIntWideningMacroConstructor {{

template<typename ElemType>
%(class_name)s<ElemType>::%(class_name)s(ExtMachInst _machInst)
    : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s)
{
    %(set_reg_idx_arr)s;
    %(constructor)s;
    const int64_t vlmul = vtype_vlmul(_machInst.vtype8);
    // Todo: move to Decode template
    panic_if(vlmul == 3, "LMUL=8 is illegal for widening inst");
    // when LMUL setted as m1, need to split to 2 micro insts
    const uint32_t num_microops = 1 << std::max<int64_t>(0, vlmul + 1);

    int32_t tmp_vl = this->vl;
    const int32_t t_micro_vlmax = vtype_VLMAX(_machInst.vtype8, true);
    const int32_t micro_vlmax = vlmul < 0 ? t_micro_vlmax : t_micro_vlmax / 2;
    int32_t micro_vl = std::min(tmp_vl, micro_vlmax);
    StaticInstPtr microop;

    if (micro_vl == 0) {
        microop = new VectorNopMicroInst(_machInst);
        this->microops.push_back(microop);
    }
    for (int i = 0; i < num_microops && micro_vl > 0; ++i) {
        microop = new %(class_name)sMicro<ElemType>(_machInst, micro_vl, i);
        microop->setDelayedCommit();
        this->microops.push_back(microop);
        micro_vl = std::min(tmp_vl -= micro_vlmax, micro_vlmax);
    }

    this->microops.front()->setFirstMicroop();
    this->microops.back()->setLastMicroop();
}

}};

def template VectorIntWideningMicroDeclare {{

template<typename ElemType>
class %(class_name)s : public %(base_class)s
{
private:
    // vs1, vs2, vs3(old_vd), vm for *.vv, *.vx
    RegId srcRegIdxArr[4];
    RegId destRegIdxArr[1];
    bool vm;
public:
    %(class_name)s(ExtMachInst _machInst, uint8_t _microVl,
                   uint8_t _microIdx);
    Fault execute(ExecContext* xc, trace::InstRecord* traceData)const override;
    using %(base_class)s::generateDisassembly;
};

}};

def template VectorIntWideningMicroConstructor {{

template<typename ElemType>
%(class_name)s<ElemType>::%(class_name)s(ExtMachInst _machInst,
        uint8_t _microVl, uint8_t _microIdx)
    : %(base_class)s("%(mnemonic)s", _machInst,
                     %(op_class)s, _microVl, _microIdx)
{
    this->vm = _machInst.vm;
    %(set_reg_idx_arr)s;
    _numSrcRegs = 0;
    _numDestRegs = 0;
    %(set_dest_reg_idx)s;
    %(set_src_reg_idx)s;
}

}};

def template VectorIntWideningMicroExecute {{

template <typename ElemType>
Fault
%(class_name)s<ElemType>::execute(ExecContext* xc,
                                  trace::InstRecord* traceData) const
{
    using vu [[maybe_unused]] = std::make_unsigned_t<ElemType>;
    using vi [[maybe_unused]] = std::make_signed_t<ElemType>;
    using vwu [[maybe_unused]] = typename double_width<vu>::type;
    using vwi [[maybe_unused]] = typename double_width<vi>::type;
    [[maybe_unused]] constexpr size_t sew = sizeof(vu) * 8;

    if (machInst.vill)
        return std::make_shared<IllegalInstFault>("VILL is set", machInst);
    const int64_t vlmul = vtype_vlmul(machInst.vtype8);
    const int32_t t_micro_vlmax = vtype_VLMAX(machInst.vtype8, true);
    const int32_t micro_vlmax = vlmul < 0 ? t_micro_vlmax : t_micro_vlmax / 2;
    [[maybe_unused]] const size_t offset =
        (this->microIdx % 2 == 0) ? 0 : micro_vlmax;

    %(op_decl)s;
    %(op_rd)s;
    %(vm_decl_rd)s;
    %(copy_old_vd)s;
    %(code)s;
    %(op_wb)s;
    return NoFault;
}

}};

def template VectorIntNarrowingMicroExecute {{

template <typename ElemType>
Fault
%(class_name)s<ElemType>::execute(ExecContext* xc,
                                  trace::InstRecord* traceData) const
{
    using vu [[maybe_unused]] = std::make_unsigned_t<ElemType>;
    using vi [[maybe_unused]] = std::make_signed_t<ElemType>;
    using vwu [[maybe_unused]] = typename double_width<vu>::type;
    using vwi [[maybe_unused]] = typename double_width<vi>::type;
    [[maybe_unused]] constexpr size_t sew = sizeof(vu) * 8;

    if (machInst.vill)
        return std::make_shared<IllegalInstFault>("VILL is set", machInst);
    const int64_t vlmul = vtype_vlmul(machInst.vtype8);
    const int32_t t_micro_vlmax = vtype_VLMAX(machInst.vtype8, true);
    const int32_t micro_vlmax = vlmul < 0 ? t_micro_vlmax : t_micro_vlmax / 2;
    [[maybe_unused]] const size_t offset =
        (this->microIdx % 2 == 0) ? 0 : micro_vlmax;

    %(op_decl)s;
    %(op_rd)s;
    %(vm_decl_rd)s;
    %(copy_old_vd)s;
    %(code)s;
    %(op_wb)s;
    return NoFault;
}

}};

def template VectorIntWideningDecodeBlock {{

switch(machInst.vtype8.vsew) {
case 0b000: return new %(class_name)s<uint8_t>(machInst);
case 0b001: return new %(class_name)s<uint16_t>(machInst);
case 0b010: return new %(class_name)s<uint32_t>(machInst);
default: GEM5_UNREACHABLE;
}

}};

def template VectorFloatMacroDeclare {{

template<typename ElemType>
class %(class_name)s : public %(base_class)s {
private:
    %(reg_idx_arr_decl)s;
public:
    %(class_name)s(ExtMachInst _machInst);
    using %(base_class)s::generateDisassembly;
};

}};

def template VectorFloatMacroConstructor {{
template<typename ElemType>
%(class_name)s<ElemType>::%(class_name)s(ExtMachInst _machInst)
    : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s)
{
    %(set_reg_idx_arr)s;
    %(constructor)s;
    const uint32_t num_microops = vtype_regs_per_group(vtype);
    int32_t tmp_vl = this->vl;
    const int32_t micro_vlmax = vtype_VLMAX(_machInst.vtype8, true);
    int32_t micro_vl = std::min(tmp_vl, micro_vlmax);
    StaticInstPtr microop;

    if (micro_vl == 0) {
        microop = new VectorNopMicroInst(_machInst);
        this->microops.push_back(microop);
    }
    for (int i = 0; i < num_microops && micro_vl > 0; ++i) {
        microop = new %(class_name)sMicro<ElemType>(_machInst, micro_vl, i);
        microop->setDelayedCommit();
        this->microops.push_back(microop);
        micro_vl = std::min(tmp_vl -= micro_vlmax, micro_vlmax);
    }

    this->microops.front()->setFirstMicroop();
    this->microops.back()->setLastMicroop();
}
}};

def template VectorFloatMicroDeclare {{

template<typename ElemType>
class %(class_name)s : public %(base_class)s
{
private:
    // vs1, vs2, vs3(old_vd), vm
    RegId srcRegIdxArr[4];
    RegId destRegIdxArr[1];
    bool vm;
public:
    %(class_name)s(ExtMachInst _machInst,
        uint8_t _microVl, uint8_t _microIdx);
    Fault execute(ExecContext* xc, trace::InstRecord* traceData)const override;
    using %(base_class)s::generateDisassembly;
};

}};

def template VectorFloatMicroConstructor {{
template<typename ElemType>
%(class_name)s<ElemType>::%(class_name)s(ExtMachInst _machInst,
                                         uint8_t _microVl, uint8_t _microIdx)
    : %(base_class)s("%(mnemonic)s", _machInst,
                     %(op_class)s, _microVl, _microIdx)
{
    this->vm = _machInst.vm;
    %(set_reg_idx_arr)s;
    _numSrcRegs = 0;
    _numDestRegs = 0;
    %(set_dest_reg_idx)s;
    %(set_src_reg_idx)s;
}

}};

def template VectorFloatMicroExecute {{

template <typename ElemType>
Fault
%(class_name)s<ElemType>::execute(ExecContext* xc,
                                  trace::InstRecord* traceData) const
{
    using et = ElemType;
    using vu = decltype(et::v);
    if (machInst.vill)
        return std::make_shared<IllegalInstFault>("VILL is set", machInst);

    VRM_REQUIRED;

    %(op_decl)s;
    %(op_rd)s;
    %(vm_decl_rd)s;
    %(copy_old_vd)s;
    %(code)s;
    %(op_wb)s;

    return NoFault;
}

}};

def template VectorFloatDecodeBlock {{

switch(machInst.vtype8.vsew) {
case 0b010: return new %(class_name)s<float32_t>(machInst);
case 0b011: return new %(class_name)s<float64_t>(machInst);
default: GEM5_UNREACHABLE;
}

}};

def template VectorFloatCvtMacroDeclare {{

template<typename ElemType>
class %(class_name)s : public %(base_class)s {
private:
    %(reg_idx_arr_decl)s;
public:
    %(class_name)s(ExtMachInst _machInst);
    std::string generateDisassembly(Addr pc,
        const loader::SymbolTable *symtab) const override
    {
        std::stringstream ss;
        ss << mnemonic << ' ' << registerName(destRegIdx(0)) << ", "
            << registerName(srcRegIdx(0));
        if (machInst.vm == 0) ss << ", v0.t";
        return ss.str();
    }
};

}};

def template VectorFloatCvtMicroDeclare {{

template<typename ElemType>
class %(class_name)s : public %(base_class)s
{
private:
    RegId srcRegIdxArr[3];
    RegId destRegIdxArr[1];
    bool vm;
public:
    %(class_name)s(ExtMachInst _machInst,
        uint8_t _microVl, uint8_t _microIdx);
    Fault execute(ExecContext* xc, trace::InstRecord* traceData)const override;
    std::string generateDisassembly(Addr pc,
        const loader::SymbolTable *symtab) const override
    {
        std::stringstream ss;
        ss << mnemonic << ' ' << registerName(destRegIdx(0)) << ", "
            << registerName(srcRegIdx(0));
        if (machInst.vm == 0) ss << ", v0.t";
        return ss.str();
    }
};

}};


def template VectorFloatWideningMicroExecute {{

template <typename ElemType>
Fault
%(class_name)s<ElemType>::execute(ExecContext* xc,
                                  trace::InstRecord* traceData) const
{
    using et = ElemType;
    using vu [[maybe_unused]] = decltype(et::v);
    using ewt = typename double_width<et>::type;
    using vwu = decltype(ewt::v);

    if (machInst.vill)
        return std::make_shared<IllegalInstFault>("VILL is set", machInst);

    VRM_REQUIRED;

    const int64_t vlmul = vtype_vlmul(machInst.vtype8);
    const int32_t t_micro_vlmax = vtype_VLMAX(machInst.vtype8, true);
    const int32_t micro_vlmax = vlmul < 0 ? t_micro_vlmax : t_micro_vlmax / 2;
    [[maybe_unused]] const size_t offset =
        (this->microIdx % 2 == 0) ? 0 : micro_vlmax;

    %(op_decl)s;
    %(op_rd)s;
    %(vm_decl_rd)s;
    %(copy_old_vd)s;
    %(code)s;
    %(op_wb)s;
    return NoFault;
}

}};

def template VectorFloatNarrowingMicroExecute {{

template <typename ElemType>
Fault
%(class_name)s<ElemType>::execute(ExecContext* xc,
                                  trace::InstRecord* traceData) const
{
    using et = ElemType;
    using vu [[maybe_unused]] = decltype(et::v);
    using ewt = typename double_width<et>::type;
    using vwu = decltype(ewt::v);

    if (machInst.vill)
        return std::make_shared<IllegalInstFault>("VILL is set", machInst);

    VRM_REQUIRED;

    const int64_t vlmul = vtype_vlmul(machInst.vtype8);
    const int32_t t_micro_vlmax = vtype_VLMAX(machInst.vtype8, true);
    const int32_t micro_vlmax = vlmul < 0 ? t_micro_vlmax : t_micro_vlmax / 2;
    [[maybe_unused]] const size_t offset =
        (this->microIdx % 2 == 0) ? 0 : micro_vlmax;

    %(op_decl)s;
    %(op_rd)s;
    %(vm_decl_rd)s;
    %(copy_old_vd)s;
    %(code)s;
    %(op_wb)s;
    return NoFault;
}

}};

def template VectorFloatWideningDecodeBlock {{

switch(machInst.vtype8.vsew) {
case 0b010: return new %(class_name)s<float32_t>(machInst);
default: GEM5_UNREACHABLE;
}

}};

def template ViotaMacroDeclare {{

template<typename ElemType>
class %(class_name)s : public %(base_class)s {
private:
    int cnt = 0;
    %(reg_idx_arr_decl)s;
public:
    %(class_name)s(ExtMachInst _machInst);
    using %(base_class)s::generateDisassembly;
};

}};


def template ViotaMacroConstructor {{

template<typename ElemType>
%(class_name)s<ElemType>::%(class_name)s(ExtMachInst _machInst)
    : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s)
{
    %(set_reg_idx_arr)s;
    %(constructor)s;
    const uint32_t num_microops = vtype_regs_per_group(vtype);
    int32_t tmp_vl = this->vl;
    const int32_t micro_vlmax = vtype_VLMAX(_machInst.vtype8, true);
    int32_t micro_vl = std::min(tmp_vl, micro_vlmax);

    StaticInstPtr microop;

    // Allow one empty micro op to hold IsLastMicroop flag
    for (int i = 0; i < num_microops && micro_vl >= 0; ++i) {
        microop = new %(class_name)sMicro<ElemType>(_machInst, micro_vl, i,
            &cnt);
        microop->setDelayedCommit();
        this->microops.push_back(microop);
        micro_vl = std::min(tmp_vl -= micro_vlmax, micro_vlmax);
    }

    this->microops.front()->setFirstMicroop();
    this->microops.back()->setLastMicroop();
}

}};

def template ViotaMicroDeclare {{

template<typename ElemType>
class %(class_name)s : public %(base_class)s
{
private:
    RegId srcRegIdxArr[4];
    RegId destRegIdxArr[1];
    bool vm;
    int* cnt;
public:
    %(class_name)s(ExtMachInst _machInst, uint8_t _microVl,
                   uint8_t _microIdx, int* cnt);
    Fault execute(ExecContext* xc, trace::InstRecord* traceData)const override;
    using %(base_class)s::generateDisassembly;
};

}};

def template ViotaMicroConstructor {{

template<typename ElemType>
%(class_name)s<ElemType>::%(class_name)s(ExtMachInst _machInst,
    uint8_t _microVl, uint8_t _microIdx, int* cnt)
    : %(base_class)s("%(mnemonic)s", _machInst,
                     %(op_class)s, _microVl, _microIdx)
{
    this->vm = _machInst.vm;
    this->cnt = cnt;
    %(set_reg_idx_arr)s;
    _numSrcRegs = 0;
    _numDestRegs = 0;
    %(set_dest_reg_idx)s;
    %(set_src_reg_idx)s;
    setSrcRegIdx(_numSrcRegs++, vecRegClass[_machInst.vs2]);
}

}};

def template ViotaMicroExecute {{

template <typename ElemType>
Fault
%(class_name)s<ElemType>::execute(ExecContext* xc,
                                  trace::InstRecord* traceData) const
{
    using vu [[maybe_unused]] = std::make_unsigned_t<ElemType>;
    using vi [[maybe_unused]] = std::make_signed_t<ElemType>;
    if (machInst.vill)
        return std::make_shared<IllegalInstFault>("VILL is set", machInst);
    %(op_decl)s;
    %(op_rd)s;
    %(vm_decl_rd)s;
    %(copy_old_vd)s;
    %(code)s;
    %(op_wb)s;
    return NoFault;
}

}};


def template Vector1Vs1VdMaskConstructor {{

template<typename ElemType>
%(class_name)s<ElemType>::%(class_name)s(ExtMachInst _machInst)
    : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s)
{
    this->vm = _machInst.vm;
    %(set_reg_idx_arr)s;
    %(set_dest_reg_idx)s;
    %(set_src_reg_idx)s;
    %(set_vm_idx)s;
}

}};

def template Vector1Vs1VdMaskExecute {{

template<typename ElemType>
Fault
%(class_name)s<ElemType>::execute(ExecContext* xc,
                                  trace::InstRecord* traceData) const
{
    using vu = uint8_t;
    if (machInst.vill)
        return std::make_shared<IllegalInstFault>("VILL is set", machInst);
    %(op_decl)s;
    %(op_rd)s;
    %(vm_decl_rd)s;
    %(copy_old_vd)s;
    %(code)s;
    %(op_wb)s;
    return NoFault;
};

}};

def template Vector1Vs1RdMaskDeclare {{

template<typename ElemType>
class %(class_name)s : public %(base_class)s {
private:
    RegId srcRegIdxArr[2];
    RegId destRegIdxArr[1];
    bool vm;
public:
    %(class_name)s(ExtMachInst _machInst);
    Fault execute(ExecContext* xc, trace::InstRecord* traceData)const override;
    using %(base_class)s::generateDisassembly;
};

}};

def template Vector1Vs1RdMaskConstructor {{

template<typename ElemType>
%(class_name)s<ElemType>::%(class_name)s(ExtMachInst _machInst)
    : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s)
{
    this->vm = _machInst.vm;
    %(set_reg_idx_arr)s;
    %(constructor)s;
    %(set_vm_idx)s;
}

}};

def template Vector1Vs1RdMaskExecute {{

template<typename ElemType>
Fault
%(class_name)s<ElemType>::execute(ExecContext* xc,
                                  trace::InstRecord* traceData) const
{
    using vu [[maybe_unused]] = std::make_unsigned_t<ElemType>;
    using vi [[maybe_unused]] = std::make_signed_t<ElemType>;
    if (machInst.vill)
        return std::make_shared<IllegalInstFault>("VILL is set", machInst);
    %(op_rd)s;
    uint64_t Rd = 0;
    %(vm_decl_rd)s;
    %(code)s;
    %(op_wb)s;
    return NoFault;
};

}};

def template VectorIntMaskMacroDeclare {{

template<typename ElemType>
class %(class_name)s : public %(base_class)s {
private:
    %(reg_idx_arr_decl)s;
public:
    %(class_name)s(ExtMachInst _machInst);
    using %(base_class)s::generateDisassembly;
};

}};

def template VectorIntMaskMacroConstructor {{

template<typename ElemType>
%(class_name)s<ElemType>::%(class_name)s(ExtMachInst _machInst)
    : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s)
{
    %(set_reg_idx_arr)s;
    %(constructor)s;
    const uint32_t num_microops = vtype_regs_per_group(vtype);
    int32_t tmp_vl = this->vl;
    const int32_t micro_vlmax = vtype_VLMAX(_machInst.vtype8, true);
    int32_t micro_vl = std::min(tmp_vl, micro_vlmax);
    StaticInstPtr microop;

    if (micro_vl == 0) {
        microop = new VectorNopMicroInst(_machInst);
        this->microops.push_back(microop);
    }
    for (int i = 0; i < num_microops && micro_vl > 0; ++i) {
        microop = new %(class_name)sMicro<ElemType>(_machInst, micro_vl, i);
        microop->setDelayedCommit();
        this->microops.push_back(microop);
        micro_vl = std::min(tmp_vl -= micro_vlmax, micro_vlmax);
    }
    microop = new VMaskMergeMicroInst<ElemType>(_machInst, _machInst.vd,
        this->microops.size());
    this->microops.push_back(microop);

    this->microops.front()->setFirstMicroop();
    this->microops.back()->setLastMicroop();
}

}};

def template VectorIntMaskMicroDeclare {{

template<typename ElemType>
class %(class_name)s : public %(base_class)s
{
private:
    // vs1(rs1), vs2, old_vd, v0 for *.vv[m] or *.vx[m]
    // vs2, old_vd, v0 for *.vi[m]
    RegId srcRegIdxArr[4];
    RegId destRegIdxArr[1];
    bool vm;
public:
    %(class_name)s(ExtMachInst _machInst,
                   uint8_t _microVl, uint8_t _microIdx);
    Fault execute(ExecContext* xc, trace::InstRecord* traceData)const override;
    using %(base_class)s::generateDisassembly;
};

}};

def template VectorIntMaskMicroConstructor {{

template<typename ElemType>
%(class_name)s<ElemType>::%(class_name)s(ExtMachInst _machInst,
                                         uint8_t _microVl, uint8_t _microIdx)
: %(base_class)s("%(mnemonic)s", _machInst,
                 %(op_class)s, _microVl, _microIdx)
{
    this->vm = _machInst.vm;
    %(set_reg_idx_arr)s;
    _numSrcRegs = 0;
    _numDestRegs = 0;
    %(set_dest_reg_idx)s;
    %(set_src_reg_idx)s;
}

}};

def template VectorIntMaskMicroExecute {{

template <typename ElemType>
Fault
%(class_name)s<ElemType>::execute(ExecContext* xc,
                                  trace::InstRecord* traceData) const
{
    using vu [[maybe_unused]] = std::make_unsigned_t<ElemType>;
    using vi [[maybe_unused]] = std::make_signed_t<ElemType>;
    if (machInst.vill)
        return std::make_shared<IllegalInstFault>("VILL is set", machInst);

    %(op_decl)s;
    %(op_rd)s;
    %(vm_decl_rd)s;
    %(copy_old_vd)s;

    constexpr uint16_t bit_offset = VLENB / sizeof(ElemType);
    const uint16_t offset = bit_offset * microIdx;

    %(code)s;
    %(op_wb)s;
    return NoFault;
}

}};

def template VectorFloatMaskMacroDeclare {{

template<typename ElemType>
class %(class_name)s : public %(base_class)s {
private:
    %(reg_idx_arr_decl)s;
public:
    %(class_name)s(ExtMachInst _machInst);
    using %(base_class)s::generateDisassembly;
};

}};

def template VectorFloatMaskMacroConstructor {{

template<typename ElemType>
%(class_name)s<ElemType>::%(class_name)s(ExtMachInst _machInst)
    : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s)
{
    %(set_reg_idx_arr)s;
    %(constructor)s;
    const uint32_t num_microops = vtype_regs_per_group(vtype);
    int32_t tmp_vl = this->vl;
    const int32_t micro_vlmax = vtype_VLMAX(_machInst.vtype8, true);
    int32_t micro_vl = std::min(tmp_vl, micro_vlmax);
    StaticInstPtr microop;

    if (micro_vl == 0) {
        microop = new VectorNopMicroInst(_machInst);
        this->microops.push_back(microop);
    }
    for (int i = 0; i < num_microops && micro_vl > 0; ++i) {
        microop = new %(class_name)sMicro<ElemType>(_machInst, micro_vl, i);
        microop->setDelayedCommit();
        this->microops.push_back(microop);
        micro_vl = std::min(tmp_vl -= micro_vlmax, micro_vlmax);
    }
    microop = new VMaskMergeMicroInst<ElemType>(_machInst, _machInst.vd,
        this->microops.size());
    this->microops.push_back(microop);

    this->microops.front()->setFirstMicroop();
    this->microops.back()->setLastMicroop();
}

}};

def template VectorFloatMaskMicroDeclare {{

template<typename ElemType>
class %(class_name)s : public %(base_class)s
{
private:
    // vs1(rs1), vs2, old_vd, v0 for *.vv or *.vf
    RegId srcRegIdxArr[4];
    RegId destRegIdxArr[1];
    bool vm;
public:
    %(class_name)s(ExtMachInst _machInst,
                   uint8_t _microVl, uint8_t _microIdx);
    Fault execute(ExecContext* xc, trace::InstRecord* traceData)const override;
    using %(base_class)s::generateDisassembly;
};

}};

def template VectorFloatMaskMicroConstructor {{

template<typename ElemType>
%(class_name)s<ElemType>::%(class_name)s(ExtMachInst _machInst,
                                         uint8_t _microVl, uint8_t _microIdx)
: %(base_class)s("%(mnemonic)s", _machInst,
                 %(op_class)s, _microVl, _microIdx)
{
    this->vm = _machInst.vm;
    %(set_reg_idx_arr)s;
    _numSrcRegs = 0;
    _numDestRegs = 0;
    %(set_dest_reg_idx)s;
    %(set_src_reg_idx)s;
}

}};

def template VectorFloatMaskMicroExecute {{

template <typename ElemType>
Fault
%(class_name)s<ElemType>::execute(ExecContext* xc,
                                  trace::InstRecord* traceData) const
{
    using et = ElemType;
    using vu = decltype(et::v);
    if (machInst.vill)
        return std::make_shared<IllegalInstFault>("VILL is set", machInst);

    %(op_decl)s;
    %(op_rd)s;
    %(vm_decl_rd)s;
    %(copy_old_vd)s;

    constexpr uint16_t bit_offset = VLENB / sizeof(ElemType);
    const uint16_t offset = bit_offset * microIdx;

    %(code)s;
    %(op_wb)s;
    return NoFault;
}

}};

def template VMvWholeMacroDeclare {{

class %(class_name)s : public %(base_class)s {
private:
    %(reg_idx_arr_decl)s;
public:
    %(class_name)s(ExtMachInst _machInst);
    using %(base_class)s::generateDisassembly;
};

}};

def template VMvWholeMacroConstructor {{

%(class_name)s::%(class_name)s(ExtMachInst _machInst)
    : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s)
{
    %(set_reg_idx_arr)s;
    %(constructor)s;
    const uint32_t num_microops = _machInst.simm3 + 1;
    StaticInstPtr microop;

    for (int i = 0; i < num_microops; ++i) {
        microop = new %(class_name)sMicro(_machInst, 0, i);
        microop->setDelayedCommit();
        this->microops.push_back(microop);
    }

    this->microops.front()->setFirstMicroop();
    this->microops.back()->setLastMicroop();
}

}};

def template VMvWholeMicroDeclare {{

class %(class_name)s : public %(base_class)s
{
private:
    RegId srcRegIdxArr[1];
    RegId destRegIdxArr[1];
    bool vm;
public:
    %(class_name)s(ExtMachInst _machInst, uint8_t _microVl,
                   uint8_t _microIdx);
    Fault execute(ExecContext* xc, trace::InstRecord* traceData)const override;
    using %(base_class)s::generateDisassembly;
};

}};

def template VMvWholeMicroConstructor {{

%(class_name)s::%(class_name)s(ExtMachInst _machInst,
                               uint8_t _microVl, uint8_t _microIdx)
    : %(base_class)s("%(mnemonic)s", _machInst,
                     %(op_class)s, _microVl, _microIdx)
{
    %(set_reg_idx_arr)s;
    _numSrcRegs = 0;
    _numDestRegs = 0;
    setDestRegIdx(_numDestRegs++, vecRegClass[_machInst.vd + _microIdx]);
    _numTypedDestRegs[VecRegClass]++;
    setSrcRegIdx(_numSrcRegs++, vecRegClass[_machInst.vs2 + _microIdx]);
}

}};

def template VMvWholeMicroExecute {{

Fault
%(class_name)s::execute(ExecContext* xc, trace::InstRecord* traceData) const
{
    // TODO: Check register alignment.
    // TODO: If vd is equal to vs2 the instruction is an architectural NOP.
    %(op_decl)s;
    %(op_rd)s;
    for (size_t i = 0; i < (VLEN / 64); i++) {
        %(code)s;
    }
    %(op_wb)s;
    return NoFault;
}

}};

def template VectorMaskDeclare {{

template<typename ElemType>
class %(class_name)s : public %(base_class)s {
private:
    RegId srcRegIdxArr[3];
    RegId destRegIdxArr[1];
public:
    %(class_name)s(ExtMachInst _machInst);
    Fault execute(ExecContext* xc, trace::InstRecord* traceData)const override;
    using %(base_class)s::generateDisassembly;
};

}};

def template VectorMaskConstructor {{

template<typename ElemType>
%(class_name)s<ElemType>::%(class_name)s(ExtMachInst _machInst)
    : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s)
{
    %(set_reg_idx_arr)s;
    %(set_dest_reg_idx)s;
    %(set_src_reg_idx)s;
}

}};

def template VectorMaskExecute {{

template<typename ElemType>
Fault
%(class_name)s<ElemType>::execute(ExecContext* xc,
                                  trace::InstRecord* traceData) const
{
    using vu = uint8_t;

    if (machInst.vill)
        return std::make_shared<IllegalInstFault>("VILL is set", machInst);

    %(op_decl)s;
    %(op_rd)s;
    // TODO: remove it
    %(copy_old_vd)s;
    %(code)s;
    %(op_wb)s;

    return NoFault;
};

}};

def template VectorMaskDecodeBlock {{

return new %(class_name)s<uint8_t>(machInst);

}};

def template VectorNonSplitDeclare {{

template<typename ElemType>
class %(class_name)s : public %(base_class)s {
private:
    RegId srcRegIdxArr[2];
    RegId destRegIdxArr[1];
public:
    %(class_name)s(ExtMachInst _machInst);
    Fault execute(ExecContext* xc, trace::InstRecord* traceData)const override;
    using %(base_class)s::generateDisassembly;
};

}};

def template VectorNonSplitConstructor {{

template<typename ElemType>
%(class_name)s<ElemType>::%(class_name)s(ExtMachInst _machInst)
    : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s)
{
    %(set_reg_idx_arr)s;
    %(constructor)s;
    %(set_vm_idx)s;
}

}};

def template VectorIntNonSplitExecute {{

template <typename ElemType>
Fault
%(class_name)s<ElemType>::execute(ExecContext* xc,
                                    trace::InstRecord* traceData) const
{
    using vu [[maybe_unused]] = std::make_unsigned_t<ElemType>;
    using vi [[maybe_unused]] = std::make_signed_t<ElemType>;
    if (machInst.vill)
        return std::make_shared<IllegalInstFault>("VILL is set", machInst);
    %(op_decl)s;
    %(op_rd)s;
    %(vm_decl_rd)s;
    %(code)s;
    %(op_wb)s;
    return NoFault;
}

}};

def template VectorFloatNonSplitExecute {{

template <typename ElemType>
Fault
%(class_name)s<ElemType>::execute(ExecContext* xc,
                                    trace::InstRecord* traceData) const
{
    using et = ElemType;
    using vu = decltype(et::v);

    if (machInst.vill)
        return std::make_shared<IllegalInstFault>("VILL is set", machInst);
    %(op_decl)s;
    %(op_rd)s;
    %(vm_decl_rd)s;
    %(code)s;
    %(op_wb)s;
    return NoFault;
}

}};

def template VectorReduceMacroDeclare {{

template<typename ElemType>
class %(class_name)s : public %(base_class)s {
private:
    %(reg_idx_arr_decl)s;
public:
    %(class_name)s(ExtMachInst _machInst);
    using %(base_class)s::generateDisassembly;
};

}};

def template VectorReduceMacroConstructor {{

template<typename ElemType>
%(class_name)s<ElemType>::%(class_name)s(ExtMachInst _machInst)
    : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s)
{
    %(set_reg_idx_arr)s;
    %(constructor)s;
    const uint32_t num_microops = vtype_regs_per_group(vtype);
    int32_t tmp_vl = this->vl;
    const int32_t micro_vlmax = vtype_VLMAX(_machInst.vtype8, true);
    int32_t micro_vl = std::min(tmp_vl, micro_vlmax);
    StaticInstPtr microop;

    if (micro_vl == 0) {
        microop = new VectorNopMicroInst(_machInst);
        this->microops.push_back(microop);
    }
    for (int i = 0; i < num_microops && micro_vl > 0; ++i) {
        microop = new %(class_name)sMicro<ElemType>(_machInst, micro_vl, i);
        microop->setDelayedCommit();
        this->microops.push_back(microop);
        micro_vl = std::min(tmp_vl -= micro_vlmax, micro_vlmax);
    }
    this->microops.front()->setFirstMicroop();
    this->microops.back()->setLastMicroop();
}

}};

def template VectorReduceMicroDeclare {{

template<typename ElemType>
class %(class_name)s : public %(base_class)s
{
private:
    // vs2, vs1, vd, vm
    RegId srcRegIdxArr[4];
    RegId destRegIdxArr[1];
    bool vm;
public:
    %(class_name)s(ExtMachInst _machInst,
                   uint8_t _microVl, uint8_t _microIdx);
    Fault execute(ExecContext* xc, trace::InstRecord* traceData)const override;
    using %(base_class)s::generateDisassembly;
};

}};

def template VectorReduceMicroConstructor {{

template<typename ElemType>
%(class_name)s<ElemType>::%(class_name)s(ExtMachInst _machInst,
                                         uint8_t _microVl, uint8_t _microIdx)
: %(base_class)s("%(mnemonic)s", _machInst,
                 %(op_class)s, _microVl, _microIdx)
{
    this->vm = _machInst.vm;
    %(set_reg_idx_arr)s;
    _numSrcRegs = 0;
    _numDestRegs = 0;
    %(set_dest_reg_idx)s;
    %(set_src_reg_idx)s;
}

}};

def template VectorReduceIntMicroExecute {{

template <typename ElemType>
Fault
%(class_name)s<ElemType>::execute(ExecContext* xc,
                                  trace::InstRecord* traceData) const
{
    %(type_def)s;
    if (machInst.vill)
        return std::make_shared<IllegalInstFault>("VILL is set", machInst);

    %(op_decl)s;
    %(op_rd)s;
    %(vm_decl_rd)s;
    %(copy_old_vd)s;

    auto reduce_loop =
        [&, this](const auto& f, const auto* _, const auto* vs2) {
            ElemType microop_result = this->microIdx != 0 ? old_Vd[0] : Vs1[0];
            for (uint32_t i = 0; i < this->microVl; i++) {
                uint32_t ei = i + vtype_VLMAX(vtype, true) * this->microIdx;
                if (this->vm || elem_mask(v0, ei)) {
                    microop_result = f(microop_result, Vs2[i]);
                }
            }
            return microop_result;
        };

    %(code)s;
    %(op_wb)s;
    return NoFault;
}

}};

def template VectorReduceFloatMicroExecute {{

template <typename ElemType>
Fault
%(class_name)s<ElemType>::execute(ExecContext* xc,
                                  trace::InstRecord* traceData) const
{
    %(type_def)s;
    if (machInst.vill)
        return std::make_shared<IllegalInstFault>("VILL is set", machInst);

    %(op_decl)s;
    %(op_rd)s;
    %(vm_decl_rd)s;
    %(copy_old_vd)s;

    Vd[0] = this->microIdx != 0 ? old_Vd[0] : Vs1[0];

    auto reduce_loop =
        [&, this](const auto& f, const auto* _, const auto* vs2) {
            vu tmp_val = Vd[0];
            for (uint32_t i = 0; i < this->microVl; i++) {
                uint32_t ei = i + vtype_VLMAX(vtype, true) * this->microIdx;
                if (this->vm || elem_mask(v0, ei)) {
                    tmp_val = f(tmp_val, Vs2[i]).v;
                }
            }
            return tmp_val;
        };

    %(code)s;
    %(op_wb)s;
    return NoFault;
}

}};

def template VectorReduceFloatWideningMicroExecute {{

template <typename ElemType>
Fault
%(class_name)s<ElemType>::execute(ExecContext* xc,
                                  trace::InstRecord* traceData) const
{
    %(type_def)s;
    if (machInst.vill)
        return std::make_shared<IllegalInstFault>("VILL is set", machInst);

    %(op_decl)s;
    %(op_rd)s;
    %(vm_decl_rd)s;
    %(copy_old_vd)s;

    Vd[0] = this->microIdx != 0 ? old_Vd[0] : Vs1[0];

    auto reduce_loop =
        [&, this](const auto& f, const auto* _, const auto* vs2) {
            vwu tmp_val = Vd[0];
            for (uint32_t i = 0; i < this->microVl; i++) {
                uint32_t ei = i + vtype_VLMAX(vtype, true) * this->microIdx;
                if (this->vm || elem_mask(v0, ei)) {
                    tmp_val = f(tmp_val, Vs2[i]).v;
                }
            }
            return tmp_val;
        };

    %(code)s;
    %(op_wb)s;
    return NoFault;
}

}};

def template VectorGatherMacroDeclare {{

template<typename ElemType, typename IndexType>
class %(class_name)s : public %(base_class)s{
private:
    %(reg_idx_arr_decl)s;
public:
    %(class_name)s(ExtMachInst _machInst);
    using %(base_class)s::generateDisassembly;
};

}};

def template VectorGatherMacroConstructor {{

template<typename ElemType, typename IndexType>
%(class_name)s<ElemType, IndexType>::%(class_name)s(ExtMachInst _machInst)
    : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s)
{
    %(set_reg_idx_arr)s;
    %(constructor)s;
    constexpr uint32_t vd_eewb = sizeof(ElemType);
    constexpr uint32_t vs2_eewb = sizeof(ElemType);
    constexpr uint32_t vs1_eewb = sizeof(IndexType);
    constexpr bool vs1_split = vd_eewb > vs1_eewb;
    const int8_t lmul = vtype_vlmul(vtype);
    const int8_t vs1_emul = lmul +
        (vs1_split ? -(vs2_eewb / vs1_eewb) : vs1_eewb / vs2_eewb);
    const uint8_t vs2_vregs = lmul < 0 ? 1 : 1 << lmul;
    const uint8_t vs1_vregs = vs1_emul < 0 ? 1 : 1 << vs1_emul;
    const uint8_t vd_vregs = vs2_vregs;
    const int32_t micro_vlmax = VLENB / std::max(vd_eewb, vs1_eewb);
    int32_t remaining_vl = this->vl;
    int32_t micro_vl = std::min(remaining_vl, micro_vlmax);
    StaticInstPtr microop;

    if (micro_vl == 0) {
        microop = new VectorNopMicroInst(_machInst);
        this->microops.push_back(microop);
    }
    for (uint8_t i = 0; i < std::max(vs1_vregs, vd_vregs) && micro_vl > 0;
            i++) {
        for (uint8_t j = 0; j < vs2_vregs; j++) {
            microop = new %(class_name)sMicro<ElemType, IndexType>(
                _machInst, micro_vl, i * vs2_vregs + j);
            microop->setDelayedCommit();
            this->microops.push_back(microop);
        }
        micro_vl = std::min(remaining_vl -= micro_vlmax, micro_vlmax);
    }

    this->microops.front()->setFirstMicroop();
    this->microops.back()->setLastMicroop();
}

}};

def template VectorGatherMicroDeclare {{

template<typename ElemType, typename IndexType>
class %(class_name)s : public %(base_class)s
{
private:
    // vs2, vs1, vd, vm
    RegId srcRegIdxArr[4];
    RegId destRegIdxArr[1];
    bool vm;
public:
    %(class_name)s(ExtMachInst _machInst,
                   uint8_t _microVl, uint8_t _microIdx);
    Fault execute(ExecContext* xc, trace::InstRecord* traceData)const override;
    using %(base_class)s::generateDisassembly;
};

}};

def template VectorGatherMicroConstructor {{

template<typename ElemType, typename IndexType>
%(class_name)s<ElemType, IndexType>::%(class_name)s(ExtMachInst _machInst,
    uint8_t _microVl, uint8_t _microIdx)
: %(base_class)s("%(mnemonic)s", _machInst,
                 %(op_class)s, _microVl, _microIdx)
{
    this->vm = _machInst.vm;
    %(set_reg_idx_arr)s;
    _numSrcRegs = 0;
    _numDestRegs = 0;
    [[maybe_unused]] constexpr uint32_t vd_eewb = sizeof(ElemType);
    [[maybe_unused]] constexpr uint32_t vs2_eewb = sizeof(ElemType);
    [[maybe_unused]] constexpr uint32_t vs1_eewb = sizeof(IndexType);
    constexpr uint8_t vs1_split_num = (vd_eewb + vs1_eewb - 1) / vs1_eewb;
    constexpr uint8_t vd_split_num = (vs1_eewb + vd_eewb - 1) / vd_eewb;
    const int8_t lmul = vtype_vlmul(vtype);
    const uint8_t vs2_vregs = lmul < 0 ? 1 : 1 << lmul;
    [[maybe_unused]] const uint8_t vs2_idx = _microIdx % vs2_vregs;
    [[maybe_unused]] const uint8_t vs1_idx =
        _microIdx / vs2_vregs / vs1_split_num;
    [[maybe_unused]] const uint8_t vd_idx =
        _microIdx / vs2_vregs / vd_split_num;
    %(set_dest_reg_idx)s;
    %(set_src_reg_idx)s;
}

}};

def template VectorGatherMicroExecute {{

template <typename ElemType, typename IndexType>
Fault
%(class_name)s<ElemType, IndexType>::execute(ExecContext* xc,
                                  trace::InstRecord* traceData) const
{
    using vu [[maybe_unused]] = std::make_unsigned_t<ElemType>;
    [[maybe_unused]] constexpr size_t sew = sizeof(vu) * 8;

    if (machInst.vill)
        return std::make_shared<IllegalInstFault>("VILL is set", machInst);

    %(op_decl)s;
    %(op_rd)s;
    %(vm_decl_rd)s;
    %(copy_old_vd)s;
    const uint32_t vlmax = vtype_VLMAX(vtype);
    constexpr uint8_t vd_eewb = sizeof(ElemType);
    constexpr uint8_t vs1_eewb = sizeof(IndexType);
    constexpr uint8_t vs2_eewb = sizeof(ElemType);
    constexpr uint8_t vs1_split_num = (vd_eewb + vs1_eewb - 1) / vs1_eewb;
    constexpr uint8_t vd_split_num = (vs1_eewb + vd_eewb - 1) / vd_eewb;
    [[maybe_unused]] constexpr uint16_t vd_elems = VLENB / vd_eewb;
    [[maybe_unused]] constexpr uint16_t vs1_elems = VLENB / vs1_eewb;
    [[maybe_unused]] constexpr uint16_t vs2_elems = VLENB / vs2_eewb;
    [[maybe_unused]] const int8_t lmul = vtype_vlmul(vtype);
    [[maybe_unused]] const uint8_t vs2_vregs = lmul < 0 ? 1 : 1 << lmul;
    [[maybe_unused]] const uint8_t vs2_idx = microIdx % vs2_vregs;
    [[maybe_unused]] const uint8_t vs1_idx =
        microIdx / vs2_vregs / vs1_split_num;
    [[maybe_unused]] const uint8_t vd_idx =
        microIdx / vs2_vregs / vd_split_num;
    [[maybe_unused]] const uint16_t vs1_bias =
        vs1_elems * (vd_idx % vs1_split_num) / vs1_split_num;
    [[maybe_unused]] const uint16_t vd_bias =
        vd_elems * (vs1_idx % vd_split_num) / vd_split_num;

    %(code)s;
    %(op_wb)s;

    return NoFault;
}

}};

def template VectorGatherDecodeBlock {{

switch(machInst.vtype8.vsew) {
    case 0b000: {
        using elem_type [[maybe_unused]] = uint8_t;
        return new %(class_name)s<uint8_t, %(idx_type)s>(machInst);
    }
    case 0b001: {
        using elem_type [[maybe_unused]] = uint16_t;
        return new %(class_name)s<uint16_t, %(idx_type)s>(machInst);
    }
    case 0b010: {
        using elem_type [[maybe_unused]] = uint32_t;
        return new %(class_name)s<uint32_t, %(idx_type)s>(machInst);
    }
    case 0b011: {
        using elem_type [[maybe_unused]] = uint64_t;
        return new %(class_name)s<uint64_t, %(idx_type)s>(machInst);
    }
    default: GEM5_UNREACHABLE;
}

}};

def template VectorIntVxsatMacroDeclare {{

template<typename ElemType>
class %(class_name)s : public %(base_class)s{
private:
    %(reg_idx_arr_decl)s;
    bool vxsat = false;
public:
    %(class_name)s(ExtMachInst _machInst);
    using %(base_class)s::generateDisassembly;
};

}};

def template VectorIntVxsatMacroConstructor {{

template<typename ElemType>
%(class_name)s<ElemType>::%(class_name)s(ExtMachInst _machInst)
    : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s)
{
    %(set_reg_idx_arr)s;
    %(constructor)s;
    const uint32_t num_microops = vtype_regs_per_group(vtype);
    int32_t tmp_vl = this->vl;
    const int32_t micro_vlmax = vtype_VLMAX(_machInst.vtype8, true);
    int32_t micro_vl = std::min(tmp_vl, micro_vlmax);
    StaticInstPtr microop;

    if (micro_vl == 0) {
        microop = new VectorNopMicroInst(_machInst);
        this->microops.push_back(microop);
    }
    for (int i = 0; i < num_microops && micro_vl > 0; ++i) {
        microop = new %(class_name)sMicro<ElemType>(_machInst,
            micro_vl, i, &vxsat);
        microop->setDelayedCommit();
        this->microops.push_back(microop);
        micro_vl = std::min(tmp_vl -= micro_vlmax, micro_vlmax);
    }

    microop = new VxsatMicroInst(&vxsat, _machInst);
    microop->setFlag(StaticInst::IsSerializeAfter);
    microop->setFlag(StaticInst::IsNonSpeculative);
    this->microops.push_back(microop);
    this->microops.front()->setFirstMicroop();
    this->microops.back()->setLastMicroop();
}
}};

def template VectorIntVxsatMicroDeclare {{

template<typename ElemType>
class %(class_name)s : public %(base_class)s
{
private:
    RegId srcRegIdxArr[4];
    RegId destRegIdxArr[1];
    bool vm;
    bool* vxsatptr;
public:
    %(class_name)s(ExtMachInst _machInst, uint8_t _microVl,
                   uint8_t _microIdx, bool* vxsatptr);
    Fault execute(ExecContext* xc, trace::InstRecord* traceData)const override;
    using %(base_class)s::generateDisassembly;
};

}};

def template VectorIntVxsatMicroConstructor {{

template<typename ElemType>
%(class_name)s<ElemType>::%(class_name)s(ExtMachInst _machInst,
    uint8_t _microVl, uint8_t _microIdx, bool* vxsatptr)
    : %(base_class)s("%(mnemonic)s", _machInst,
                     %(op_class)s, _microVl, _microIdx)
{
    this->vm = _machInst.vm;
    this->vxsatptr = vxsatptr;
    %(set_reg_idx_arr)s;
    _numSrcRegs = 0;
    _numDestRegs = 0;
    %(set_dest_reg_idx)s;
    %(set_src_reg_idx)s;
}

}};

def template VectorReduceIntWideningMicroExecute {{

template <typename ElemType>
Fault
%(class_name)s<ElemType>::execute(ExecContext* xc,
                                  trace::InstRecord* traceData) const
{
    using vu [[maybe_unused]] = std::make_unsigned_t<ElemType>;
    using vi [[maybe_unused]] = std::make_signed_t<ElemType>;
    using vwu [[maybe_unused]] = typename double_width<vu>::type;
    using vwi [[maybe_unused]] = typename double_width<vi>::type;

    if (machInst.vill)
        return std::make_shared<IllegalInstFault>("VILL is set", machInst);

    %(op_decl)s;
    %(op_rd)s;
    %(vm_decl_rd)s;
    %(copy_old_vd)s;

    Vd[0] = this->microIdx != 0 ? old_Vd[0] : Vs1[0];

    auto reduce_loop =
        [&, this](const auto& f, const auto* _, const auto* vs2) {
            vwu tmp_val = Vd[0];
            for (uint32_t i = 0; i < this->microVl; i++) {
                uint32_t ei = i + vtype_VLMAX(vtype, true) * this->microIdx;
                if (this->vm || elem_mask(v0, ei)) {
                    tmp_val = f(tmp_val, Vs2[i]);
                }
            }
            return tmp_val;
        };

    %(code)s;
    %(op_wb)s;
    return NoFault;
}

}};

def template VectorSlideMacroDeclare {{

template<typename ElemType>
class %(class_name)s : public %(base_class)s {
private:
    %(reg_idx_arr_decl)s;
public:
    %(class_name)s(ExtMachInst _machInst);
    using %(base_class)s::generateDisassembly;
};

}};

def template VectorSlideUpMacroConstructor {{

template<typename ElemType>
%(class_name)s<ElemType>::%(class_name)s(ExtMachInst _machInst)
    : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s)
{
    %(set_reg_idx_arr)s;
    %(constructor)s;
    const uint32_t num_microops = vtype_regs_per_group(vtype);
    int32_t tmp_vl = this->vl;
    const int32_t micro_vlmax = vtype_VLMAX(_machInst.vtype8, true);
    int32_t micro_vl = std::min(tmp_vl, micro_vlmax);
    StaticInstPtr microop;

    if (micro_vl == 0) {
        microop = new VectorNopMicroInst(_machInst);
        this->microops.push_back(microop);
    }
    // Todo static filter out useless uop
    int micro_idx = 0;
    for (int i = 0; i < num_microops && micro_vl > 0; ++i) {
        for (int j = 0; j <= i; ++j) {
            microop = new %(class_name)sMicro<ElemType>(
                _machInst, micro_vl, micro_idx++, i, j);
            microop->setDelayedCommit();
            this->microops.push_back(microop);
        }
        micro_vl = std::min(tmp_vl -= micro_vlmax, micro_vlmax);
    }
    this->microops.front()->setFirstMicroop();
    this->microops.back()->setLastMicroop();
}

}};

def template VectorSlideDownMacroConstructor {{

template<typename ElemType>
%(class_name)s<ElemType>::%(class_name)s(ExtMachInst _machInst)
    : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s)
{
    %(set_reg_idx_arr)s;
    %(constructor)s;
    const uint32_t num_microops = vtype_regs_per_group(vtype);
    int32_t tmp_vl = this->vl;
    const int32_t micro_vlmax = vtype_VLMAX(_machInst.vtype8, true);
    int32_t micro_vl = std::min(tmp_vl, micro_vlmax);
    StaticInstPtr microop;

    if (micro_vl == 0) {
        microop = new VectorNopMicroInst(_machInst);
        this->microops.push_back(microop);
    }
    // Todo static filter out useless uop
    int micro_idx = 0;
    for (int i = 0; i < num_microops && micro_vl > 0; ++i) {
        for (int j = i; j < num_microops; ++j) {
            microop = new %(class_name)sMicro<ElemType>(
                _machInst, micro_vl, micro_idx++, i, j);
            microop->setDelayedCommit();
            this->microops.push_back(microop);
        }
        micro_vl = std::min(tmp_vl -= micro_vlmax, micro_vlmax);
    }
    this->microops.front()->setFirstMicroop();
    this->microops.back()->setLastMicroop();
}

}};

def template VectorSlideMicroDeclare {{

template<typename ElemType>
class %(class_name)s : public %(base_class)s
{
private:
    // vs2, vs1, vs3(old_vd), vm for *.vv, *.vx
    // vs2, (old_vd), vm for *.vi
    RegId srcRegIdxArr[4];
    RegId destRegIdxArr[1];
    bool vm;
public:
    %(class_name)s(ExtMachInst _machInst, uint8_t _microVl,
        uint8_t _microIdx, uint8_t _vdIdx, uint8_t _vs2Idx);
    Fault execute(ExecContext* xc, trace::InstRecord* traceData)const override;
    using %(base_class)s::generateDisassembly;
};

}};

def template VectorSlideMicroConstructor {{

template<typename ElemType>
%(class_name)s<ElemType>::%(class_name)s(ExtMachInst _machInst,
        uint8_t _microVl, uint8_t _microIdx, uint8_t _vdIdx, uint8_t _vs2Idx)
    : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s, _microVl,
        _microIdx, _vdIdx, _vs2Idx)
{
    this->vm = _machInst.vm;
    %(set_reg_idx_arr)s;
    _numSrcRegs = 0;
    _numDestRegs = 0;
    %(set_dest_reg_idx)s;
    %(set_src_reg_idx)s;
}

}};

def template VectorSlideMicroExecute {{

template<typename ElemType>
Fault
%(class_name)s<ElemType>::execute(ExecContext* xc,
                                  trace::InstRecord* traceData) const
{
    using vu [[maybe_unused]] = std::make_unsigned_t<ElemType>;
    using vi [[maybe_unused]] = std::make_signed_t<ElemType>;

    if (machInst.vill)
        return std::make_shared<IllegalInstFault>("VILL is set", machInst);
    [[maybe_unused]]const uint32_t vlmax = vtype_VLMAX(vtype);

    %(op_decl)s;
    %(op_rd)s;
    %(vm_decl_rd)s;
    %(copy_old_vd)s;
    %(code)s;
    %(op_wb)s;

    return NoFault;
};

}};

def template VectorFloatSlideMicroExecute {{

template<typename ElemType>
Fault
%(class_name)s<ElemType>::execute(ExecContext* xc,
                                  trace::InstRecord* traceData) const
{
    using et = ElemType;
    using vu = decltype(et::v);

    if (machInst.vill)
        return std::make_shared<IllegalInstFault>("VILL is set", machInst);
    [[maybe_unused]]const uint32_t vlmax = vtype_VLMAX(vtype);

    %(op_decl)s;
    %(op_rd)s;
    %(vm_decl_rd)s;
    %(copy_old_vd)s;
    %(code)s;
    %(op_wb)s;

    return NoFault;
};

}};