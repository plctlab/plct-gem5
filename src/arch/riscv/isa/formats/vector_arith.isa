// -*- mode:c++ -*-

// Copyright (c) 2022 PLCT Lab
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are
// met: redistributions of source code must retain the above copyright
// notice, this list of conditions and the following disclaimer;
// redistributions in binary form must reproduce the above copyright
// notice, this list of conditions and the following disclaimer in the
// documentation and/or other materials provided with the distribution;
// neither the name of the copyright holders nor the names of its
// contributors may be used to endorse or promote products derived from
// this software without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
// "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.


let {{
    def setDestWrapper(destRegId):
        return "setDestRegIdx(_numDestRegs++, " + destRegId + ");\n" + \
               "_numTypedDestRegs[VecRegClass]++;\n"
    def setSrcWrapper(srcRegId):
        return "setSrcRegIdx(_numSrcRegs++, " + srcRegId + ");\n"
    def setSrcVm():
        return "if (!this->vm)\n" + \
               "    setSrcRegIdx(_numSrcRegs++, vecRegClass[0]);"
    def vmDeclAndReadData():
        return '''
            [[maybe_unused]] RiscvISA::vreg_t tmp_v0;
            [[maybe_unused]] uint8_t* v0;
            if(!machInst.vm) {
                xc->getRegOperand(this, _numSrcRegs-1, &tmp_v0);
                v0 = tmp_v0.as<uint8_t>();
            }
        '''
    def copyOldVd(vd_idx):
        return 'COPY_OLD_VD(%d);' % vd_idx
    def loopWrapper(code, micro_inst = True):
        if micro_inst:
            upper_bound = "this->microVl"
        else:
            upper_bound = "(uint32_t)machInst.vl"
        return '''
            for (uint32_t i = 0; i < %s; i++) {
                %s
            }
        ''' % (upper_bound, code)
    def maskCondWrapper(code):
        return "if (this->vm || elem_mask(v0, ei)) {\n" + \
               code + "}\n"
    def eiDeclarePrefix(code, widening = False):
        if widening:
            return '''
            uint32_t ei = i + micro_vlmax * this->microIdx;
            ''' + code
        else:
            return '''
            uint32_t ei = i + vtype_VLMAX(vtype, true) * this->microIdx;
            ''' + code

    def fflags_wrapper(code):
        return '''
        RegVal FFLAGS = xc->readMiscReg(MISCREG_FFLAGS);
        std::feclearexcept(FE_ALL_EXCEPT);
        ''' + code + '''
        FFLAGS |= softfloat_exceptionFlags;
        softfloat_exceptionFlags = 0;
        xc->setMiscReg(MISCREG_FFLAGS, FFLAGS);
        '''

    def VI_CHECK_SSS(flag = True):
        if flag == True:
            return '''
            const float vflmul = Vflmul(vtype_vlmul(machInst.vtype8));
            if (vflmul > 1) {
                if(!(is_aligned(machInst.vd, vflmul)&&
                    is_aligned(machInst.vs2, vflmul)&&
                    is_aligned(machInst.vs1, vflmul))) {
                    std::string error =
                        csprintf("Unaligned Vd, Vs2 or Vs1 group");
                    return std::make_shared<IllegalInstFault>(error, machInst);
                }
            }
            '''
        else:
            return '''
            const float vflmul = Vflmul(vtype_vlmul(machInst.vtype8));
            if (vflmul > 1) {
                if(!(is_aligned(machInst.vd, vflmul)&&
                is_aligned(machInst.vs2, vflmul))) {
                    std::string error =
                        csprintf("Unaligned Vd or Vs2 group");
                    return std::make_shared<IllegalInstFault>(error, machInst);
                }
            }
            '''

    def VI_CHECK_DSS(flag = True):
        if flag == True:
            return '''
            const float vflmul = Vflmul(vlmul);
            const size_t vsew = sizeof(vu) * 8;
            if(vflmul > 4 || vsew*2 > gem5::RiscvISA::ELEN){
                std::string error =
                    csprintf("Illegal LMUL or SEW");
                return std::make_shared<IllegalInstFault>(error, machInst);
            }
            if(!(is_aligned(machInst.vd, 2*vflmul)&&
                is_aligned(machInst.vs2, 2*vflmul)&&
                is_aligned(machInst.vs1, 2*vflmul))){
                std::string error =
                    csprintf("Unaligned Vd, Vs2 or Vs1 group");
                return std::make_shared<IllegalInstFault>(error, machInst);
            }
            if(vflmul < 1){
                if(is_overlapped(machInst.vd, 2*vflmul,
                                 machInst.vs2, 2*vflmul)||
                   is_overlapped(machInst.vd, 2*vflmul,
                                 machInst.vs1, 2*vflmul))
                {
                    std::string error =
                        csprintf(
                        "Unsupported overlap in Vd and Vs2/Vs1 group"
                        );
                    return std::make_shared<IllegalInstFault>(error,
                        machInst);
                }
            }else{
                if(is_overlapped_widen(machInst.vd, 2*vflmul,
                                       machInst.vs2, 2*vflmul)||
                   is_overlapped_widen(machInst.vd, 2*vflmul,
                                       machInst.vs1, 2*vflmul))
                {
                    std::string error =
                        csprintf(
                        "Unsupported overlap in Vd and Vs2/Vs1 group"
                        );
                    return std::make_shared<IllegalInstFault>(error,
                        machInst);
                }
            }
            '''
        elif flag == False:
            return '''
            const float vflmul = Vflmul(vlmul);
            const size_t vsew = sizeof(vu) * 8;
            if(vflmul > 4 || vsew*2 > gem5::RiscvISA::ELEN){
                std::string error =
                    csprintf("Illegal LMUL or SEW");
                return std::make_shared<IllegalInstFault>(error, machInst);
            }
            if(!(is_aligned(machInst.vd, vflmul)&&
                is_aligned(machInst.vs2, vflmul))){
                std::string error =
                    csprintf("Unaligned Vd or Vs2 group");
                return std::make_shared<IllegalInstFault>(error, machInst);
            }
            if(vflmul < 1){
                if(is_overlapped(machInst.vd, vflmul*2,
                                 machInst.vs2, vflmul*2))
                {
                    std::string error =
                        csprintf(
                        "Unsupported overlap in Vd and Vs2 group"
                        );
                    return std::make_shared<IllegalInstFault>(error,
                        machInst);
                }
            }else{
                if(is_overlapped_widen(machInst.vd, vflmul*2,
                                       machInst.vs2, vflmul*2)){
                    std::string error =
                        csprintf(
                        "Unsupported overlap in Vd and Vs2 group"
                        );
                    return std::make_shared<IllegalInstFault>(error,
                        machInst);
                }
            }
            '''
        else:
            return '''
            '''

    def VI_CHECK_DDS(flag = True):
        if flag == True:
            return '''
            const float vflmul = Vflmul(vlmul);
            const size_t vsew = sizeof(vu) * 8;
            if(vflmul > 4 || vsew*2 > gem5::RiscvISA::ELEN){
                std::string error =
                    csprintf("Illegal LMUL or SEW");
                return std::make_shared<IllegalInstFault>(error, machInst);
            }
            if(!(is_aligned(machInst.vd, vflmul*2)&&
                is_aligned(machInst.vs2, vflmul*2)&&
                is_aligned(machInst.vs1, vflmul))){
                std::string error =
                    csprintf("Unaligned Vd, Vs2 or Vs1 group");
                return std::make_shared<IllegalInstFault>(error, machInst);
            }
            if(vflmul < 1){
                if(is_overlapped(machInst.vd, vflmul*2,
                                machInst.vs1, vflmul)){
                    std::string error =
                        csprintf(
                        "Unsupported overlap in Vd and Vs1 group"
                        );
                    return std::make_shared<IllegalInstFault>(error,
                        machInst);
                }
            }else{
                if(is_overlapped_widen(machInst.vd, vflmul*2,
                                       machInst.vs1, vflmul)){
                    std::string error =
                        csprintf("Unsupported overlap in Vd and Vs1 group");
                    return std::make_shared<IllegalInstFault>(error, machInst);
                }
            }
            '''
        elif flag == False:
            return '''
            const float vflmul = Vflmul(vlmul);
            const size_t vsew = sizeof(vu) * 8;
            if(vflmul > 4 || vsew*2 > gem5::RiscvISA::ELEN){
                std::string error =
                    csprintf("Illegal LMUL or SEW");
                return std::make_shared<IllegalInstFault>(error, machInst);
            }
            if(!(is_aligned(machInst.vd, vflmul*2)&&
                is_aligned(machInst.vs2, vflmul*2))){
                std::string error =
                    csprintf("Unaligned Vd or Vs2 group");
                return std::make_shared<IllegalInstFault>(error, machInst);
            }
            '''
        else:
            return '''
            '''

    def VI_CHECK_SDS(flag = True):
        if flag == True:
            return '''
            const float vflmul = Vflmul(vlmul);
            const size_t vsew = sizeof(vu) * 8;
            if(vflmul > 4 || vsew*2 > gem5::RiscvISA::ELEN){
                std::string error =
                    csprintf("Illegal LMUL or SEW");
                return std::make_shared<IllegalInstFault>(error, machInst);
            }
            if(!(is_aligned(machInst.vd, vflmul)&&
                is_aligned(machInst.vs2, vflmul*2)&&
                is_aligned(machInst.vs1, vflmul))){
                std::string error =
                    csprintf("Unaligned Vd, Vs2 or Vs1 group");
                return std::make_shared<IllegalInstFault>(error, machInst);
            }
            if(machInst.vd != machInst.vs2){
                if(is_overlapped(machInst.vd, vflmul, machInst.vs2, vflmul*2)){
                    std::string error =
                        csprintf("Unsupported overlap in Vd and Vs2 group");
                    return std::make_shared<IllegalInstFault>(error, machInst);
                }
            }
            '''
        else:
            return '''
            const float vflmul = Vflmul(vlmul);
            const size_t vsew = sizeof(vu) * 8;
            if(vflmul > 4 || vsew*2 > gem5::RiscvISA::ELEN){
                std::string error =
                    csprintf("Illegal LMUL or SEW");
                return std::make_shared<IllegalInstFault>(error, machInst);
            }
            if(!(is_aligned(machInst.vd, vflmul)&&
                is_aligned(machInst.vs2, vflmul*2))){
                std::string error =
                    csprintf("Unaligned Vd or Vs2 group");
                return std::make_shared<IllegalInstFault>(error, machInst);
            }
            if(machInst.vd != machInst.vs2){
                if(is_overlapped(machInst.vd, vflmul, machInst.vs2, vflmul*2)){
                    std::string error =
                        csprintf("Unsupported overlap in Vd and Vs2 group");
                    return std::make_shared<IllegalInstFault>(error, machInst);
                }
            }
            '''

    def VI_CHECK_REDUCTION(wideflag = True):
        if wideflag == True:
            return '''
    const float vflmul = Vflmul(vtype_vlmul(machInst.vtype8));
    const size_t vsew = sizeof(vu) * 8;
    if(vsew*2 > gem5::RiscvISA::ELEN){
        std::string error =
            csprintf("Illegal SEW");
        return std::make_shared<IllegalInstFault>(error, machInst);
    }
    if(!(is_aligned(machInst.vs2, vflmul))){
        std::string error =
            csprintf("Unaligned Vs2 group");
        return std::make_shared<IllegalInstFault>(error, machInst);
    }
            '''
        else:
            return '''
    const float vflmul = Vflmul(vtype_vlmul(machInst.vtype8));
    if(!(is_aligned(machInst.vs2, vflmul))){
        std::string error =
            csprintf("Unaligned Vs2 group");
        return std::make_shared<IllegalInstFault>(error, machInst);
    }
            '''

    def VI_CHECK_MSS(flag):
        if flag == True:
            return'''
            const float vflmul = Vflmul(vtype_vlmul(machInst.vtype8));
            if(machInst.vd != machInst.vs2){
                if(is_overlapped(machInst.vd, 1, machInst.vs2, vflmul)){
                    std::string error =
                        csprintf("Unsupported overlap in Vd and Vs2 group");
                    return std::make_shared<IllegalInstFault>(error, machInst);
                }
            }
            if(!(is_aligned(machInst.vs2, vflmul)&&
                is_aligned(machInst.vs1, vflmul))){
                std::string error =
                    csprintf("Unaligned Vs2 or Vs1 group");
                return std::make_shared<IllegalInstFault>(error, machInst);
            }
            if(machInst.vd != machInst.vs1){
                if(is_overlapped(machInst.vd, 1, machInst.vs1, vflmul)){
                    std::string error =
                        csprintf("Unsupported overlap in Vd and Vs1 group");
                    return std::make_shared<IllegalInstFault>(error, machInst);
                }
            }
            '''
        else:
            return '''
            const float vflmul = Vflmul(vtype_vlmul(machInst.vtype8));
            if(machInst.vd != machInst.vs2){
                if(is_overlapped(machInst.vd, 1, machInst.vs2, vflmul)){
                    std::string error =
                        csprintf("Unsupported overlap in Vd and Vs2 group");
                    return std::make_shared<IllegalInstFault>(error, machInst);
                }
            }
            if(!(is_aligned(machInst.vs2, vflmul))){
                std::string error =
                    csprintf("Unaligned Vs2 group");
                return std::make_shared<IllegalInstFault>(error, machInst);
            }
            '''

    def VI_CHECK_VRGATHER(flag):
        if flag == True:
            return '''
            const float vflmul = Vflmul(vtype_vlmul(machInst.vtype8));
            if(!(is_aligned(machInst.vd, vflmul)&&
                is_aligned(machInst.vs2, vflmul)&&
                is_aligned(machInst.vs1, vflmul))) {
                std::string error =
                    csprintf("Unaligned Vd, Vs2 or Vs1 group");
                return std::make_shared<IllegalInstFault>(error, machInst);
            }
            if(machInst.vd==machInst.vs2 || machInst.vd==machInst.vs1){
                std::string error =
                    csprintf("Vd is the same as Vs2/Vs1");
                return std::make_shared<IllegalInstFault>(error, machInst);
            }
            '''
        elif flag == False:
            return '''
            const float vflmul = Vflmul(vtype_vlmul(machInst.vtype8));
            if(!(is_aligned(machInst.vd, vflmul)&&
                is_aligned(machInst.vs2, vflmul))) {
                std::string error =
                    csprintf("Unaligned Vd, Vs2 or Vs1 group");
                return std::make_shared<IllegalInstFault>(error, machInst);
            }
            if(machInst.vd==machInst.vs2){
                std::string error =
                    csprintf("Vd is the same as Vs2");
                return std::make_shared<IllegalInstFault>(error, machInst);
            }
            '''
        else:
            return '''
            const float vflmul = Vflmul(vtype_vlmul(machInst.vtype8));
            const float vemul = (16.0 / sew * vflmul);
            if(!(vemul<=8 && vemul>=0.125)){
                std::string error =
                    csprintf("Illegal vemul");
                return std::make_shared<IllegalInstFault>(error, machInst);
            }
            if(!(is_aligned(machInst.vd, vflmul)&&
                is_aligned(machInst.vs2, vflmul)&&
                is_aligned(machInst.vs1, vemul))) {
                std::string error =
                    csprintf("Unaligned Vd, Vs2 or Vs1 group");
                return std::make_shared<IllegalInstFault>(error, machInst);
            }
            if(machInst.vd==machInst.vs2){
                std::string error =
                    csprintf("Vd is the same as Vs2");
                return std::make_shared<IllegalInstFault>(error, machInst);
            }
            if(is_overlapped(machInst.vd, vflmul, machInst.vs1, vemul)){
                std::string error =
                    csprintf("Unsupported overlap in Vd and Vs2 group");
                return std::make_shared<IllegalInstFault>(error, machInst);
            }
            '''

    def VMV_CHECK():
        return '''
        const uint64_t vd = machInst.vd;
        const uint64_t vs2 = machInst.vs2;
        const uint64_t len = machInst.vs1 + 1;
        if(!(is_aligned(vd, len)&&is_aligned(vs2, len))) {
            std::string error =
                csprintf("Unaligned Vd, Vs2 or Vs1 group");
            return std::make_shared<IllegalInstFault>(error, machInst);
        }
        '''

    def VI_VV_EXT_CHECK(div):
        return '''
        if(machInst.vd==machInst.vs2){
            std::string error =
                csprintf("Vd is equal to Vs2");
            return std::make_shared<IllegalInstFault>(error, machInst);
        }
        size_t sew = sizeof(vu) * 8;
        const float vflmul = Vflmul(vtype_vlmul(machInst.vtype8));
        uint64_t div = %d;
        uint64_t from = sew / div;
        if(!(from >= 8 && from <= 64)){
            std::string error =
                csprintf("Invalid vsew");
            return std::make_shared<IllegalInstFault>(error, machInst);
        }
        if(!((vflmul / div) >= 0.125 && (vflmul / div) <= 8)){
            std::string error =
                csprintf("Invalid vflmul");
            return std::make_shared<IllegalInstFault>(error, machInst);
        }
        if(!(is_aligned(machInst.vd, vflmul)&&
            is_aligned(machInst.vs2, vflmul/div))){
             std::string error =
                csprintf("Unaligned Vd and Vs2 group");
            return std::make_shared<IllegalInstFault>(error, machInst);
        }
        if(vflmul/div < 1){
            if(is_overlapped(machInst.vd, vflmul,
                             machInst.vs2, vflmul/div)){
                std::string error =
                    csprintf("Unsupported overlap in Vd and Vs2 group");
                return std::make_shared<IllegalInstFault>(error, machInst);
            }
        }else{
            if(is_overlapped_widen(machInst.vd, vflmul,
                                   machInst.vs2, vflmul/div)){
                std::string error =
                    csprintf("Unsupported overlap in Vd and Vs2 group");
                return std::make_shared<IllegalInstFault>(error, machInst);
            }
        }
        ''' %(div)

    def VI_CHECK_SLIDE(flag):
        if flag == True:
            return '''
            const float vflmul = Vflmul(vtype_vlmul(machInst.vtype8));
            if(!(is_aligned(machInst.vd, vflmul)&&
                is_aligned(machInst.vs2, vflmul))) {
                std::string error =
                    csprintf("Unaligned Vd, Vs2 or Vs1 group");
                return std::make_shared<IllegalInstFault>(error, machInst);
            }
            if(machInst.vd == machInst.vs2){
                std::string error =
                    csprintf("Vd is equal to Vs2");
                return std::make_shared<IllegalInstFault>(error, machInst);
            }
            '''
        else:
            return '''
            const float vflmul = Vflmul(vtype_vlmul(machInst.vtype8));
            if(!(is_aligned(machInst.vd, vflmul)&&
                is_aligned(machInst.vs2, vflmul))) {
                std::string error =
                    csprintf("Unaligned Vd, Vs2 or Vs1 group");
                return std::make_shared<IllegalInstFault>(error, machInst);
            }
            '''

    def VI_CHECK_LD_INDEX(elt):
        return '''
        const uint64_t nf = machInst.nf + 1;
        const int NVPR = 32;
        const uint64_t elt = %s;
        if(elt>gem5::RiscvISA::ELEN){
            std::string error =
                csprintf("Invalid elt and ELEN");
            return std::make_shared<IllegalInstFault>(error, machInst);
        }
        const float vflmul = Vflmul(vtype_vlmul(machInst.vtype8));
        const size_t vsew = sizeof(vu) * 8;
        const float vemul = ((float)elt / vsew * vflmul);
        if(vemul < 0.125 || vemul > 8){
            std::string error =
                csprintf("Invalid LMUL and SEW");
            return std::make_shared<IllegalInstFault>(error, machInst);
        }
        if(!(is_aligned(machInst.vd, vflmul)&&
            is_aligned(machInst.vs2, vemul))) {
            std::string error =
                csprintf("Unaligned Vd, Vs2 or Vs1 group");
            return std::make_shared<IllegalInstFault>(error, machInst);
        }
        const uint64_t flmul = vflmul < 1 ? 1 : vflmul;

        if(!((nf*flmul)<=(NVPR/4) && (machInst.vd+nf*flmul)<=NVPR)) {
            std::string error =
                csprintf("Unaligned Vd group");
            return std::make_shared<IllegalInstFault>(error, machInst);
        }
        for (uint64_t idx = 0; idx < nf; ++idx) {
            uint64_t seg_vd = machInst.vd + flmul * idx;
            if(elt > vsew){
                if (seg_vd != machInst.vs2) {
                    if(is_overlapped(seg_vd, vflmul,
                             machInst.vs2, vemul)){
                        std::string error =
                            csprintf(
                                "Unsupported overlap in Vd and Vs2 group"
                            );
                        return std::make_shared<IllegalInstFault>
                            (error, machInst);
                    }
                }
            }else if (elt < vsew) {
                if (vemul < 1) {
                    if(is_overlapped(seg_vd, vflmul, machInst.vs2, vemul)){
                        std::string error =
                            csprintf(
                                "Unsupported overlap in Vd and Vs2 group"
                            );
                        return std::make_shared<IllegalInstFault>
                            (error, machInst);
                    }
                } else {
                    if(is_overlapped_widen(seg_vd,vflmul,machInst.vs2,vemul))
                    {
                        std::string error =
                            csprintf(
                                "Unsupported overlap in Vd and Vs2 group"
                            );
                        return std::make_shared<IllegalInstFault>
                            (error, machInst);
                    }
                }
            }
            if (nf >= 2) {
                if(is_overlapped(seg_vd, vflmul, machInst.vs2, vemul)){
                    std::string error =
                        csprintf("Unsupported overlap in Vd and Vs2 group");
                    return std::make_shared<IllegalInstFault>(error, machInst);
                }
            }
        }
        ''' %(elt)

    def VI_CHECK_ST_INDEX(elt):
        return '''
        const uint64_t nf = machInst.nf + 1;
        const int NVPR = 32;
        const uint64_t elt = %s;
        if(elt>gem5::RiscvISA::ELEN){
            std::string error =
                csprintf("Invalid elt and ELEN");
            return std::make_shared<IllegalInstFault>(error, machInst);
        }
        const float vflmul = Vflmul(vtype_vlmul(machInst.vtype8));
        const size_t vsew = sizeof(vu) * 8;
        const float vemul = ((float)elt / vsew * vflmul);
        if(vemul < 0.125 || vemul > 8){
            std::string error =
                csprintf("Invalid LMUL and SEW");
            return std::make_shared<IllegalInstFault>(error, machInst);
        }
        if(!(is_aligned(machInst.vd, vflmul)&&
            is_aligned(machInst.vs2, vemul))) {
            std::string error =
                csprintf("Unaligned Vd, Vs2 or Vs1 group");
            return std::make_shared<IllegalInstFault>(error, machInst);
        }
        if(!(is_aligned(machInst.vd, vflmul)&&
            is_aligned(machInst.vs2, vemul))) {
            std::string error =
                csprintf("Unaligned Vd, Vs2 or Vs1 group");
            return std::make_shared<IllegalInstFault>(error, machInst);
        }
        const uint64_t flmul = vflmul < 1 ? 1 : vflmul;

        if(!((nf*flmul)<=(NVPR/4) && (machInst.vd+nf*flmul)<=NVPR)) {
            std::string error =
                csprintf("Unaligned Vd group");
            return std::make_shared<IllegalInstFault>(error, machInst);
        }
        ''' %(elt)

    def VI_CHECK_LOAD(elt, is_mask):
        return '''
        const uint64_t nf = machInst.nf + 1;
        const float vflmul = Vflmul(vtype_vlmul(machInst.vtype8));
        const size_t vsew = vtype_SEW(machInst.vtype8);
        const int NVPR = 32;
        bool is_mask = %s;
        uint64_t elt = %s;
        uint64_t veew = is_mask ? 1 : elt;
        float vemul = is_mask ? 1 : ((float)veew / vsew * vflmul);
        uint64_t emul = vemul < 1 ? 1 : vemul;
        if(vemul < 0.125 || vemul > 8){
            std::string error =
                csprintf("Invalid LMUL and SEW");
            return std::make_shared<IllegalInstFault>(error, machInst);
        }
        if(!(is_aligned(machInst.vd, vemul))) {
            std::string error =
                csprintf("Unaligned Vd group");
            return std::make_shared<IllegalInstFault>(error, machInst);
        }
        if(!((nf*emul)<=(NVPR/4) && (machInst.vd+nf*emul)<=NVPR)) {
            std::string error =
                csprintf("Invalid Vd group");
            return std::make_shared<IllegalInstFault>(error, machInst);
        }
        if(veew > gem5::RiscvISA::ELEN){
            std::string error =
                csprintf("Invalid veew and ELEN");
            return std::make_shared<IllegalInstFault>(error, machInst);
        }
        ''' %(is_mask, elt)

    def VI_CHECK_STORE(elt, is_mask):
        return VI_CHECK_LOAD(elt, is_mask)

    def VI_CHECK_LD_WHOLE(elt):
        return '''
        uint64_t elt = %s;
        const uint64_t nf = machInst.nf;
        if(elt>gem5::RiscvISA::ELEN){
            std::string error =
                csprintf("Invalid elt and ELEN");
            return std::make_shared<IllegalInstFault>(error, machInst);
        }
        if(!(is_aligned(machInst.vd, nf+1))) {
            std::string error =
                csprintf("Unaligned Vd group");
            return std::make_shared<IllegalInstFault>(error, machInst);
        }
        ''' %(elt)

    def VI_CHECK_ST_WHOLE():
        return '''
        const uint64_t nf = machInst.nf;
        if(!(is_aligned(machInst.vd, nf+1))) {
            std::string error =
                csprintf("Unaligned Vd group");
            return std::make_shared<IllegalInstFault>(error, machInst);
        }
        '''

}};


def format VectorIntFormat(code, category, *flags) {{
    macroop_class_name = 'VectorArithMacroInst'
    microop_class_name = 'VectorArithMicroInst'

    if name == "vid_v" :
        macroop_class_name = 'VectorVMUNARY0MacroInst'
        microp_class_name = 'VectorVMUNARY0MicroInst'

    iop = InstObjParams(name, Name, macroop_class_name, {'code': code},
                        flags)
    inst_name, inst_suffix = name.split("_", maxsplit=1)
    v0_required = inst_name not in ["vmv"]
    mask_cond = v0_required and (inst_suffix not in ['vvm', 'vxm', 'vim'])
    need_elem_idx = mask_cond or code.find("ei") != -1
    dest_reg_id = "vecRegClass[_machInst.vd + _microIdx]"
    vi_check_sss_flag = True

    num_src_regs = 0

    src2_reg_id = "vecRegClass[_machInst.vs2 + _microIdx]"
    num_src_regs += 1

    src1_reg_id = ""
    if category in ["OPIVV", "OPMVV"]:
        src1_reg_id = "vecRegClass[_machInst.vs1 + _microIdx]"
        num_src_regs += 1
    elif category in ["OPIVX", "OPMVX"]:
        src1_reg_id = "intRegClass[_machInst.rs1]"
        vi_check_sss_flag = False
        num_src_regs += 1
    elif category == "OPIVI":
        vi_check_sss_flag = False
        pass
    else:
        error("not supported category for VectorIntFormat: %s" % category)

    old_vd_idx = num_src_regs
    src3_reg_id = "vecRegClass[_machInst.vd + _microIdx]"

    set_dest_reg_idx = setDestWrapper(dest_reg_id)

    set_src_reg_idx = ""
    if category != "OPIVI":
        set_src_reg_idx += setSrcWrapper(src1_reg_id)
    set_src_reg_idx += setSrcWrapper(src2_reg_id)
    set_src_reg_idx += setSrcWrapper(src3_reg_id)
    if v0_required:
        set_src_reg_idx += setSrcVm()

    # code
    if mask_cond:
        code = maskCondWrapper(code)
    if need_elem_idx:
        code = eiDeclarePrefix(code)
    code = loopWrapper(code)

    vm_decl_rd = ""
    if v0_required:
        vm_decl_rd = vmDeclAndReadData()
    vi_check_sss = VI_CHECK_SSS(vi_check_sss_flag)
    microiop = InstObjParams(name + "_micro",
        Name + "Micro",
        microop_class_name,
        {'code': code,
         'set_dest_reg_idx': set_dest_reg_idx,
         'set_src_reg_idx': set_src_reg_idx,
         'vm_decl_rd': vm_decl_rd,
         'copy_old_vd': copyOldVd(old_vd_idx),
         'vi_check_sss': vi_check_sss},
        flags)

    # Because of the use of templates, we had to put all parts in header to
    # keep the compiler happy.
    header_output = \
        VectorIntMicroDeclare.subst(microiop) + \
        VectorIntMicroConstructor.subst(microiop) + \
        VectorIntMicroExecute.subst(microiop) + \
        VectorIntMacroDeclare.subst(iop) + \
        VectorIntMacroConstructor.subst(iop)

    decode_block = VectorIntDecodeBlock.subst(iop)
}};


def format VectorIntExtFormat(code, category, *flags) {{
    iop = InstObjParams(name, Name, 'VectorArithMacroInst', {'code': code},
                        flags)
    inst_name, inst_suffix = name.split("_", maxsplit=1)
    ext_div = int(inst_suffix[-1])

    old_vd_idx = 1
    dest_reg_id = "vecRegClass[_machInst.vd + _microIdx]"
    src2_reg_id = "vecRegClass[_machInst.vs2 + _microIdx / " + \
                      str(ext_div) + "]"
    src3_reg_id = "vecRegClass[_machInst.vs3 + _microIdx]"

    set_dest_reg_idx = setDestWrapper(dest_reg_id)

    set_src_reg_idx = ""
    set_src_reg_idx += setSrcWrapper(src2_reg_id)
    set_src_reg_idx += setSrcWrapper(src3_reg_id)
    set_src_reg_idx += setSrcVm()

    code = maskCondWrapper(code)
    code = eiDeclarePrefix(code)
    code = loopWrapper(code)
    vm_decl_rd = vmDeclAndReadData()

    microiop = InstObjParams(name + "_micro",
        Name + "Micro",
        'VectorArithMicroInst',
        {'code': code,
         'set_dest_reg_idx': set_dest_reg_idx,
         'set_src_reg_idx': set_src_reg_idx,
         'vm_decl_rd': vm_decl_rd,
         'copy_old_vd': copyOldVd(old_vd_idx),
         'ext_div': ext_div,
         'vi_vv_ext_check': VI_VV_EXT_CHECK(ext_div)
        },
        flags)

    # Because of the use of templates, we had to put all parts in header to
    # keep the compiler happy.
    header_output = \
        VectorIntExtMicroDeclare.subst(microiop) + \
        VectorIntMicroConstructor.subst(microiop) + \
        VectorIntExtMicroExecute.subst(microiop) + \
        VectorIntExtMacroDeclare.subst(iop) + \
        VectorIntMacroConstructor.subst(iop)

    decode_block = VectorIntDecodeBlock.subst(iop)
}};

def format VectorIntWideningFormat(code, category, *flags) {{
    iop = InstObjParams(name, Name, 'VectorArithMacroInst', {'code': code},
                        flags)
    inst_name, inst_suffix = name.split("_", maxsplit=1)
    v0_required = True
    mask_cond = v0_required
    need_elem_idx = mask_cond or code.find("ei") != -1
    old_vd_idx = 2
    dest_reg_id = "vecRegClass[_machInst.vd + _microIdx]"
    src1_reg_id = ""

    vi_check_dss_flag = None
    if category in ["OPIVV", "OPMVV"]:
        src1_reg_id = "vecRegClass[_machInst.vs1 + _microIdx / 2]"
        vi_check_dss_flag = True
    elif category in ["OPIVX", "OPMVX"]:
        src1_reg_id = "intRegClass[_machInst.rs1]"
        vi_check_dss_flag = False
    else:
        error("not supported category for VectorIntFormat: %s" % category)

    vi_check_dds_flag = None
    src2_reg_id = ""
    if inst_suffix in ["vv", "vx"]:
        src2_reg_id = "vecRegClass[_machInst.vs2 + _microIdx / 2]"
    elif inst_suffix in ["wv", "wx"]:
        src2_reg_id = "vecRegClass[_machInst.vs2 + _microIdx]"
        vi_check_dss_flag = None
        if inst_suffix == "wv":
            vi_check_dds_flag = True
        else:
            vi_check_dds_flag = False
    src3_reg_id = "vecRegClass[_machInst.vs3 + _microIdx]"

    set_dest_reg_idx = setDestWrapper(dest_reg_id)

    set_src_reg_idx = ""
    set_src_reg_idx += setSrcWrapper(src1_reg_id)
    set_src_reg_idx += setSrcWrapper(src2_reg_id)
    set_src_reg_idx += setSrcWrapper(src3_reg_id)
    if v0_required:
        set_src_reg_idx += setSrcVm()

    # code
    if mask_cond:
        code = maskCondWrapper(code)
    if need_elem_idx:
        code = eiDeclarePrefix(code, widening=True)
    code = loopWrapper(code)

    vm_decl_rd = ""
    if v0_required:
        vm_decl_rd = vmDeclAndReadData()

    microiop = InstObjParams(name + "_micro",
        Name + "Micro",
        'VectorArithMicroInst',
        {'code': code,
         'set_dest_reg_idx': set_dest_reg_idx,
         'set_src_reg_idx': set_src_reg_idx,
         'vm_decl_rd': vm_decl_rd,
         'copy_old_vd': copyOldVd(old_vd_idx),
         'vi_check_dss': VI_CHECK_DSS(vi_check_dss_flag),
         'vi_check_dds': VI_CHECK_DDS(vi_check_dds_flag)
        },
        flags)

    # Because of the use of templates, we had to put all parts in header to
    # keep the compiler happy.
    header_output = \
        VectorIntWideningMicroDeclare.subst(microiop) + \
        VectorIntWideningMicroConstructor.subst(microiop) + \
        VectorIntWideningMicroExecute.subst(microiop) + \
        VectorIntWideningMacroDeclare.subst(iop) + \
        VectorIntWideningMacroConstructor.subst(iop)

    decode_block = VectorIntWideningDecodeBlock.subst(iop)
}};

def format VectorIntNarrowingFormat(code, category, *flags) {{
    iop = InstObjParams(name, Name, 'VectorArithMacroInst', {'code': code},
                        flags)
    mask_cond = True
    need_elem_idx = True

    old_vd_idx = 2
    vi_check_sds_flag = False
    dest_reg_id = "vecRegClass[_machInst.vd + _microIdx / 2]"
    if category in ["OPIVV"]:
        src1_reg_id = "vecRegClass[_machInst.vs1 + _microIdx / 2]"
        vi_check_sds_flag = True
    elif category in ["OPIVX"]:
        src1_reg_id = "intRegClass[_machInst.rs1]"
    elif category == "OPIVI":
        old_vd_idx = 1
    else:
        error("not supported category for VectorIntFormat: %s" % category)
    src2_reg_id = "vecRegClass[_machInst.vs2 + _microIdx]"
    old_dest_reg_id = "vecRegClass[_machInst.vs3 + _microIdx / 2]"

    set_dest_reg_idx = setDestWrapper(dest_reg_id)
    set_src_reg_idx = ""
    if category != "OPIVI":
        set_src_reg_idx += setSrcWrapper(src1_reg_id)
    set_src_reg_idx += setSrcWrapper(src2_reg_id)
    set_src_reg_idx += setSrcWrapper(old_dest_reg_id)
    set_src_reg_idx += setSrcVm()
    # code
    code = maskCondWrapper(code)
    code = eiDeclarePrefix(code, widening=True)
    code = loopWrapper(code)
    vm_decl_rd = vmDeclAndReadData()

    microiop = InstObjParams(name + "_micro",
        Name + "Micro",
        'VectorArithMicroInst',
        {'code': code,
         'set_dest_reg_idx': set_dest_reg_idx,
         'set_src_reg_idx': set_src_reg_idx,
         'vm_decl_rd': vm_decl_rd,
         'copy_old_vd': copyOldVd(old_vd_idx),
         'vi_check_sds': VI_CHECK_SDS(vi_check_sds_flag)
         },
        flags)

    # Because of the use of templates, we had to put all parts in header to
    # keep the compiler happy.
    header_output = \
        VectorIntWideningMicroDeclare.subst(microiop) + \
        VectorIntWideningMicroConstructor.subst(microiop) + \
        VectorIntNarrowingMicroExecute.subst(microiop) + \
        VectorIntWideningMacroDeclare.subst(iop) + \
        VectorIntWideningMacroConstructor.subst(iop)

    decode_block = VectorIntWideningDecodeBlock.subst(iop)
}};

def format VectorIntMaskFormat(code, category, *flags) {{
    iop = InstObjParams(name,
        Name,
        'VectorArithMacroInst',
        {'code': code},
        flags)
    inst_name, inst_suffix = name.split("_", maxsplit=1)
    v0_required = not (inst_name in ["vmadc", "vmsbc"] \
        and inst_suffix in ["vv", "vx", "vi"])
    mask_cond = inst_name not in ['vmadc', 'vmsbc']
    need_elem_idx = mask_cond or code.find("ei") != -1

    old_vd_idx = 2
    vi_check_mss_flag = False
    dest_reg_id = "vecRegClass[VecMemInternalReg0 + _microIdx]"
    src1_reg_id = ""
    if category == "OPIVV":
        vi_check_mss_flag = True
        src1_reg_id = "vecRegClass[_machInst.vs1 + _microIdx]"
    elif category == "OPIVX":
        src1_reg_id = "intRegClass[_machInst.rs1]"
    elif category == "OPIVI":
        old_vd_idx = 1
    else:
        error("not supported category for VectorIntFormat: %s" % category)
    src2_reg_id = "vecRegClass[_machInst.vs2 + _microIdx]"
    old_dest_reg_id = "vecRegClass[_machInst.vd]"
    set_dest_reg_idx = setDestWrapper(dest_reg_id)
    set_src_reg_idx = ""
    if category != "OPIVI":
        set_src_reg_idx += setSrcWrapper(src1_reg_id)
    set_src_reg_idx += setSrcWrapper(src2_reg_id)
    set_src_reg_idx += setSrcWrapper(old_dest_reg_id)
    if v0_required:
        set_src_reg_idx += setSrcVm()

    #code
    if mask_cond:
        code = maskCondWrapper(code)
    if need_elem_idx:
        code = eiDeclarePrefix(code)
    code = loopWrapper(code)

    vm_decl_rd = ""
    if v0_required:
        vm_decl_rd = vmDeclAndReadData()

    microiop = InstObjParams(name + "_micro",
        Name + "Micro",
        'VectorArithMicroInst',
        {'code': code,
         'set_dest_reg_idx': set_dest_reg_idx,
         'set_src_reg_idx': set_src_reg_idx,
         'vm_decl_rd': vm_decl_rd,
         'copy_old_vd': copyOldVd(old_vd_idx),
         'vi_check_mss': VI_CHECK_MSS(vi_check_mss_flag)
         },
        flags)

    # Because of the use of templates, we had to put all parts in header to
    # keep the compiler happy.
    header_output = \
        VectorIntMaskMicroDeclare.subst(microiop) + \
        VectorIntMaskMicroConstructor.subst(microiop) + \
        VectorIntMaskMicroExecute.subst(microiop) + \
        VectorIntMaskMacroDeclare.subst(iop) + \
        VectorIntMaskMacroConstructor.subst(iop)
    decode_block = VectorIntDecodeBlock.subst(iop)
}};

def format VectorGatherFormat(code, category, *flags) {{
    inst_name, inst_suffix = name.split("_", maxsplit=1)
    if inst_name == "vrgatherei16":
        idx_type = "uint16_t"
    else:
        idx_type = "elem_type"
    iop = InstObjParams(name, Name, 'VectorArithMacroInst',
        {'idx_type': idx_type,
         'code': code},
        flags)
    old_vd_idx = 2
    dest_reg_id = "vecRegClass[_machInst.vd + vd_idx]"
    src1_reg_id = ""
    vi_check_vrather_flag = False
    if category in ["OPIVV"]:
        src1_reg_id = "vecRegClass[_machInst.vs1 + vs1_idx]"
        vi_check_vrather_flag = True
    elif category in ["OPIVX"]:
        src1_reg_id = "intRegClass[_machInst.rs1]"
    elif category == "OPIVI":
        old_vd_idx = 1
    else:
        error("not supported category for VectorIntFormat: %s" % category)
    if inst_name == "vrgatherei16":
        vi_check_vrather_flag = None
    src2_reg_id = "vecRegClass[_machInst.vs2 + vs2_idx]"
    src3_reg_id = "vecRegClass[_machInst.vs3 + vd_idx]"

    set_dest_reg_idx = setDestWrapper(dest_reg_id)

    set_src_reg_idx = ""
    if category != "OPIVI":
        set_src_reg_idx += setSrcWrapper(src1_reg_id)
    set_src_reg_idx += setSrcWrapper(src2_reg_id)
    set_src_reg_idx += setSrcWrapper(src3_reg_id)
    set_src_reg_idx += setSrcVm()

    # code
    vm_decl_rd = vmDeclAndReadData()

    microiop = InstObjParams(name + "_micro",
        Name + "Micro",
        'VectorArithMicroInst',
        {'code': code,
         'set_dest_reg_idx': set_dest_reg_idx,
         'set_src_reg_idx': set_src_reg_idx,
         'vm_decl_rd': vm_decl_rd,
         'copy_old_vd': copyOldVd(old_vd_idx),
         'idx_type': idx_type,
         'vi_check_vrather': VI_CHECK_VRGATHER(vi_check_vrather_flag)
         },
        flags)

    # Because of the use of templates, we had to put all parts in header to
    # keep the compiler happy.
    header_output = \
        VectorGatherMicroDeclare.subst(microiop) + \
        VectorGatherMicroConstructor.subst(microiop) + \
        VectorGatherMicroExecute.subst(microiop) + \
        VectorGatherMacroDeclare.subst(iop) + \
        VectorGatherMacroConstructor.subst(iop)

    decode_block = VectorGatherDecodeBlock.subst(iop)

}};

def format VectorFloatFormat(code, category, *flags) {{
    iop = InstObjParams(name, Name, 'VectorArithMacroInst', {'code': code},
                        flags)
    inst_name, inst_suffix = name.split("_", maxsplit=1)
    v0_required = inst_name not in ["vfmv"]
    mask_cond = v0_required and (inst_suffix not in ['vvm', 'vfm'])
    need_elem_idx = mask_cond or code.find("ei") != -1
    vi_check_sss_flag = False
    dest_reg_id = "vecRegClass[_machInst.vd + _microIdx]"
    src1_reg_id = ""
    if category == "OPFVV":
        src1_reg_id = "vecRegClass[_machInst.vs1 + _microIdx]"
        vi_check_sss_flag = True
    elif category == "OPFVF":
        src1_reg_id = "floatRegClass[_machInst.rs1]"
    else:
        error("not supported category for VectorFloatFormat: %s" % category)
    src2_reg_id = "vecRegClass[_machInst.vs2 + _microIdx]"
    src3_reg_id = "vecRegClass[_machInst.vs3 + _microIdx]"

    set_dest_reg_idx = setDestWrapper(dest_reg_id)

    set_src_reg_idx = ""
    set_src_reg_idx += setSrcWrapper(src1_reg_id)
    set_src_reg_idx += setSrcWrapper(src2_reg_id)
    set_src_reg_idx += setSrcWrapper(src3_reg_id)
    if v0_required:
        set_src_reg_idx += setSrcVm()
    # code
    if mask_cond:
        code = maskCondWrapper(code)
    if need_elem_idx:
        code = eiDeclarePrefix(code)
    code = loopWrapper(code)
    code = fflags_wrapper(code)

    vm_decl_rd = ""
    if v0_required:
        vm_decl_rd = vmDeclAndReadData()

    microiop = InstObjParams(name + "_micro",
        Name + "Micro",
        'VectorArithMicroInst',
        {'code': code,
         'set_dest_reg_idx': set_dest_reg_idx,
         'set_src_reg_idx': set_src_reg_idx,
         'vm_decl_rd': vm_decl_rd,
         'copy_old_vd': copyOldVd(2),
         'vi_check_sss': VI_CHECK_SSS(vi_check_sss_flag)
        },
        flags)

    # Because of the use of templates, we had to put all parts in header to
    # keep the compiler happy.
    header_output = \
        VectorFloatMicroDeclare.subst(microiop) + \
        VectorFloatMicroConstructor.subst(microiop) + \
        VectorFloatMicroExecute.subst(microiop) + \
        VectorFloatMacroDeclare.subst(iop) + \
        VectorFloatMacroConstructor.subst(iop)

    decode_block = VectorFloatDecodeBlock.subst(iop)
}};

def format VectorFloatCvtFormat(code, category, *flags) {{
    iop = InstObjParams(name, Name, 'VectorArithMacroInst', {'code': code},
                        flags)

    old_vd_idx = 1
    dest_reg_id = "vecRegClass[_machInst.vd + _microIdx]"
    src2_reg_id = "vecRegClass[_machInst.vs2 + _microIdx]"
    src3_reg_id = "vecRegClass[_machInst.vs3 + _microIdx]"

    set_dest_reg_idx = setDestWrapper(dest_reg_id)

    set_src_reg_idx = ""
    set_src_reg_idx += setSrcWrapper(src2_reg_id)
    set_src_reg_idx += setSrcWrapper(src3_reg_id)
    set_src_reg_idx += setSrcVm()
    code = maskCondWrapper(code)
    code = eiDeclarePrefix(code)
    code = loopWrapper(code)
    code = fflags_wrapper(code)

    vm_decl_rd = vmDeclAndReadData()

    microiop = InstObjParams(name + "_micro",
        Name + "Micro",
        'VectorArithMicroInst',
        {'code': code,
         'set_dest_reg_idx': set_dest_reg_idx,
         'set_src_reg_idx': set_src_reg_idx,
         'vm_decl_rd': vm_decl_rd,
         'copy_old_vd': copyOldVd(old_vd_idx),
         'vi_check_sss': VI_CHECK_SSS(False)
        },
        flags)

    # Because of the use of templates, we had to put all parts in header to
    # keep the compiler happy.
    header_output = \
        VectorFloatCvtMicroDeclare.subst(microiop) + \
        VectorFloatMicroConstructor.subst(microiop) + \
        VectorFloatMicroExecute.subst(microiop) + \
        VectorFloatCvtMacroDeclare.subst(iop) + \
        VectorFloatMacroConstructor.subst(iop)

    decode_block = VectorFloatDecodeBlock.subst(iop)
}};

def format VectorFloatWideningFormat(code, category, *flags) {{
    iop = InstObjParams(name, Name, 'VectorArithMacroInst', {'code': code},
                        flags)
    inst_name, inst_suffix = name.split("_", maxsplit=1)
    v0_required = True
    mask_cond = v0_required
    need_elem_idx = mask_cond or code.find("ei") != -1

    vi_check_dss_flag = None
    dest_reg_id = "vecRegClass[_machInst.vd + _microIdx]"
    src1_reg_id = ""
    if category in ["OPFVV"]:
        src1_reg_id = "vecRegClass[_machInst.vs1 + _microIdx / 2]"
        vi_check_dss_flag = True
    elif category in ["OPFVF"]:
        src1_reg_id = "floatRegClass[_machInst.rs1]"
        vi_check_dss_flag = False
    else:
        error("not supported category for VectorFloatFormat: %s" % category)
    src2_reg_id = ""
    vi_check_dds_flag = None
    if inst_suffix in ["vv", "vf"]:
        src2_reg_id = "vecRegClass[_machInst.vs2 + _microIdx / 2]"
    elif inst_suffix in ["wv", "wf"]:
        src2_reg_id = "vecRegClass[_machInst.vs2 + _microIdx]"
        vi_check_dss_flag = None
        if inst_suffix == "wv":
            vi_check_dds_flag = True
        else:
            vi_check_dds_flag = False
    src3_reg_id = "vecRegClass[_machInst.vs3 + _microIdx]"

    set_dest_reg_idx = setDestWrapper(dest_reg_id)

    set_src_reg_idx = ""
    set_src_reg_idx += setSrcWrapper(src1_reg_id)
    set_src_reg_idx += setSrcWrapper(src2_reg_id)
    set_src_reg_idx += setSrcWrapper(src3_reg_id)
    if v0_required:
        set_src_reg_idx += setSrcVm()

    # code
    if mask_cond:
        code = maskCondWrapper(code)
    if need_elem_idx:
        code = eiDeclarePrefix(code, widening=True)
    code = loopWrapper(code)
    code = fflags_wrapper(code)

    vm_decl_rd = ""
    if v0_required:
        vm_decl_rd = vmDeclAndReadData()

    microiop = InstObjParams(name + "_micro",
        Name + "Micro",
        'VectorArithMicroInst',
        {'code': code,
         'set_dest_reg_idx': set_dest_reg_idx,
         'set_src_reg_idx': set_src_reg_idx,
         'vm_decl_rd': vm_decl_rd,
         'copy_old_vd': copyOldVd(2),
         'vi_check_dss': VI_CHECK_DSS(vi_check_dss_flag),
         'vi_check_dds': VI_CHECK_DDS(vi_check_dds_flag)
        },
        flags)

    # Because of the use of templates, we had to put all parts in header to
    # keep the compiler happy.
    header_output = \
        VectorIntWideningMicroDeclare.subst(microiop) + \
        VectorIntWideningMicroConstructor.subst(microiop) + \
        VectorFloatWideningMicroExecute.subst(microiop) + \
        VectorIntWideningMacroDeclare.subst(iop) + \
        VectorIntWideningMacroConstructor.subst(iop)

    decode_block = VectorFloatWideningDecodeBlock.subst(iop)
}};

def format VectorFloatWideningCvtFormat(code, category, *flags) {{
    iop = InstObjParams(name, Name, 'VectorArithMacroInst', {'code': code},
                        flags)

    old_vd_idx = 1
    dest_reg_id = "vecRegClass[_machInst.vd + _microIdx]"
    src2_reg_id = "vecRegClass[_machInst.vs2 + _microIdx / 2]"
    src3_reg_id = "vecRegClass[_machInst.vs3 + _microIdx]"

    set_dest_reg_idx = setDestWrapper(dest_reg_id)

    set_src_reg_idx = ""
    set_src_reg_idx += setSrcWrapper(src2_reg_id)
    set_src_reg_idx += setSrcWrapper(src3_reg_id)
    set_src_reg_idx += setSrcVm()
    code = maskCondWrapper(code)
    code = eiDeclarePrefix(code)
    code = loopWrapper(code)
    code = fflags_wrapper(code)

    vm_decl_rd = vmDeclAndReadData()

    microiop = InstObjParams(name + "_micro",
        Name + "Micro",
        'VectorArithMicroInst',
        {'code': code,
         'set_dest_reg_idx': set_dest_reg_idx,
         'set_src_reg_idx': set_src_reg_idx,
         'vm_decl_rd': vm_decl_rd,
         'copy_old_vd': copyOldVd(old_vd_idx),
         'vi_check_dss': VI_CHECK_DSS(False),
         'vi_check_dds': VI_CHECK_DDS(None)
        },
        flags)

    # Because of the use of templates, we had to put all parts in header to
    # keep the compiler happy.
    header_output = \
        VectorFloatCvtMicroDeclare.subst(microiop) + \
        VectorFloatMicroConstructor.subst(microiop) + \
        VectorFloatWideningMicroExecute.subst(microiop) + \
        VectorFloatCvtMacroDeclare.subst(iop) + \
        VectorIntWideningMacroConstructor.subst(iop)

    decode_block = VectorFloatWideningDecodeBlock.subst(iop)
}};

def format VectorFloatNarrowingCvtFormat(code, category, *flags) {{
    iop = InstObjParams(name, Name, 'VectorArithMacroInst', {'code': code},
                        flags)

    old_vd_idx = 1
    dest_reg_id = "vecRegClass[_machInst.vd + _microIdx / 2]"
    src2_reg_id = "vecRegClass[_machInst.vs2 + _microIdx]"
    src3_reg_id = "vecRegClass[_machInst.vs3 + _microIdx / 2]"

    set_dest_reg_idx = setDestWrapper(dest_reg_id)

    set_src_reg_idx = ""
    set_src_reg_idx += setSrcWrapper(src2_reg_id)
    set_src_reg_idx += setSrcWrapper(src3_reg_id)
    set_src_reg_idx += setSrcVm()
    code = maskCondWrapper(code)
    code = eiDeclarePrefix(code)
    code = loopWrapper(code)
    code = fflags_wrapper(code)

    vm_decl_rd = vmDeclAndReadData()

    microiop = InstObjParams(name + "_micro",
        Name + "Micro",
        'VectorArithMicroInst',
        {'code': code,
         'set_dest_reg_idx': set_dest_reg_idx,
         'set_src_reg_idx': set_src_reg_idx,
         'vm_decl_rd': vm_decl_rd,
         'copy_old_vd': copyOldVd(old_vd_idx),
         'vi_check_sds': VI_CHECK_SDS(False)
        },
        flags)

    # Because of the use of templates, we had to put all parts in header to
    # keep the compiler happy.
    header_output = \
        VectorFloatCvtMicroDeclare.subst(microiop) + \
        VectorFloatMicroConstructor.subst(microiop) + \
        VectorFloatNarrowingMicroExecute.subst(microiop) + \
        VectorFloatCvtMacroDeclare.subst(iop) + \
        VectorIntWideningMacroConstructor.subst(iop)

    decode_block = VectorFloatWideningDecodeBlock.subst(iop)
}};

def format VectorFloatMaskFormat(code, category, *flags) {{
    iop = InstObjParams(name,
        Name,
        'VectorArithMacroInst',
        {'code': code},
        flags)
    dest_reg_id = "vecRegClass[VecMemInternalReg0 + _microIdx]"
    src1_reg_id = ""
    vi_check_mss_flag = False
    if category == "OPFVV":
        src1_reg_id = "vecRegClass[_machInst.vs1 + _microIdx]"
        vi_check_mss_flag = True
    elif category == "OPFVF":
        src1_reg_id = "floatRegClass[_machInst.rs1]"
    else:
        error("not supported category for VectorFloatFormat: %s" % category)
    src2_reg_id = "vecRegClass[_machInst.vs2 + _microIdx]"
    old_dest_reg_id = "vecRegClass[_machInst.vd]"
    set_dest_reg_idx = setDestWrapper(dest_reg_id)
    set_src_reg_idx = ""
    set_src_reg_idx += setSrcWrapper(src1_reg_id)
    set_src_reg_idx += setSrcWrapper(src2_reg_id)
    set_src_reg_idx += setSrcWrapper(old_dest_reg_id)
    set_src_reg_idx += setSrcVm()
    vm_decl_rd = vmDeclAndReadData()

    code = maskCondWrapper(code)
    code = eiDeclarePrefix(code)
    code = loopWrapper(code)
    code = fflags_wrapper(code)

    microiop = InstObjParams(name + "_micro",
        Name + "Micro",
        'VectorArithMicroInst',
        {'code': code,
         'set_dest_reg_idx': set_dest_reg_idx,
         'set_src_reg_idx': set_src_reg_idx,
         'vm_decl_rd': vm_decl_rd,
         'copy_old_vd': copyOldVd(2),
         'vi_check_mss': VI_CHECK_MSS(vi_check_mss_flag)
        },
        flags)

    # Because of the use of templates, we had to put all parts in header to
    # keep the compiler happy.
    header_output = \
        VectorFloatMaskMicroDeclare.subst(microiop) + \
        VectorFloatMaskMicroConstructor.subst(microiop) + \
        VectorFloatMaskMicroExecute.subst(microiop) + \
        VectorFloatMaskMacroDeclare.subst(iop) + \
        VectorFloatMaskMacroConstructor.subst(iop)
    decode_block = VectorFloatDecodeBlock.subst(iop)
}};

def format VMvWholeFormat(code, category, *flags) {{
    iop = InstObjParams(name, Name, 'VMvWholeMacroInst', {'code': code}, flags)

    microiop = InstObjParams(name + "_micro",
        Name + "Micro",
        'VMvWholeMicroInst',
        {'code': code,
         'vmv_check': VMV_CHECK()
        },
        flags)

    header_output = \
        VMvWholeMacroDeclare.subst(iop) + \
        VMvWholeMicroDeclare.subst(microiop)
    decoder_output = \
        VMvWholeMacroConstructor.subst(iop) + \
        VMvWholeMicroConstructor.subst(microiop)
    exec_output = VMvWholeMicroExecute.subst(microiop)
    decode_block = BasicDecode.subst(iop)
}};

def format ViotaFormat(code, category, *flags){{
    iop = InstObjParams(name, Name, 'VectorArithMacroInst', {'code': code},
                        flags)

    inst_name, inst_suffix = name.split("_", maxsplit=1)
    dest_reg_id = "vecRegClass[_machInst.vd + _microIdx]"
    src2_reg_id = "vecRegClass[_machInst.vs2 + _microIdx]"
    # The tail of vector mask inst should be treated as tail-agnostic.
    # We treat it with tail-undisturbed policy, since
    # the test suits only support undisturbed policy.
    old_dest_reg_id = "vecRegClass[_machInst.vd + _microIdx]"

    set_src_reg_idx = ""
    set_src_reg_idx += setSrcWrapper(src2_reg_id)
    set_src_reg_idx += setSrcWrapper(old_dest_reg_id)
    set_dest_reg_idx = setDestWrapper(dest_reg_id)
    vm_decl_rd = vmDeclAndReadData()
    set_vm_idx = setSrcVm()

    microiop = InstObjParams(name+"_micro",
        Name+"Micro",
        'VectorArithMicroInst',
        {'code': code,
         'set_dest_reg_idx': set_dest_reg_idx,
         'set_src_reg_idx': set_src_reg_idx,
         'vm_decl_rd': vm_decl_rd,
         'set_vm_idx': set_vm_idx,
         'copy_old_vd': copyOldVd(1)},
        flags)
    # Because of the use of templates, we had to put all parts in header to
    # keep the compiler happy.
    header_output = \
        ViotaMicroDeclare.subst(microiop) + \
        ViotaMicroConstructor.subst(microiop) + \
        ViotaMicroExecute.subst(microiop)+\
        ViotaMacroDeclare.subst(iop) + \
        ViotaMacroConstructor.subst(iop)

    decode_block = VectorIntDecodeBlock.subst(iop)

}};

def format Vector1Vs1VdMaskFormat(code, category, *flags){{
    inst_name, inst_suffix = name.split("_", maxsplit=1)
    dest_reg_id = "vecRegClass[_machInst.vd]"
    src2_reg_id = "vecRegClass[_machInst.vs2]"
    # The tail of vector mask inst should be treated as tail-agnostic.
    # We treat it with tail-undisturbed policy, since
    # the test suits only support undisturbed policy.
    old_dest_reg_id = "vecRegClass[_machInst.vd]"
    set_src_reg_idx = ""
    set_src_reg_idx += setSrcWrapper(src2_reg_id)
    set_src_reg_idx += setSrcWrapper(old_dest_reg_id)
    set_dest_reg_idx = setDestWrapper(dest_reg_id)
    vm_decl_rd = vmDeclAndReadData()
    set_vm_idx = setSrcVm()
    iop = InstObjParams(name,
        Name,
        'VectorNonSplitInst',
        {'code': code,
         'set_dest_reg_idx': set_dest_reg_idx,
         'set_src_reg_idx': set_src_reg_idx,
         'vm_decl_rd': vm_decl_rd,
         'set_vm_idx': set_vm_idx,
         'copy_old_vd': copyOldVd(1)},
        flags)
    # Because of the use of templates, we had to put all parts in header to
    # keep the compiler happy.
    header_output = \
        Vector1Vs1RdMaskDeclare.subst(iop) + \
        Vector1Vs1VdMaskConstructor.subst(iop) + \
        Vector1Vs1VdMaskExecute.subst(iop)

    decode_block = VectorMaskDecodeBlock.subst(iop)
}};

def format Vector1Vs1RdMaskFormat(code, category, *flags){{
    inst_name, inst_suffix = name.split("_", maxsplit=1)
    vm_decl_rd = vmDeclAndReadData()
    set_vm_idx = setSrcVm()
    iop = InstObjParams(name,
        Name,
        'VectorNonSplitInst',
        {'code': code,
         'vm_decl_rd': vm_decl_rd,
         'set_vm_idx': set_vm_idx},
        flags)
    # Because of the use of templates, we had to put all parts in header to
    # keep the compiler happy.
    header_output = \
        Vector1Vs1RdMaskDeclare.subst(iop) + \
        Vector1Vs1RdMaskConstructor.subst(iop) + \
        Vector1Vs1RdMaskExecute.subst(iop)

    decode_block = VectorMaskDecodeBlock.subst(iop)
}};

def format VectorNonSplitFormat(code, category, *flags) {{
    inst_name, inst_suffix = name.split("_", maxsplit=1)
    vm_decl_rd = ""

    set_vm_idx = ""

    if inst_name == "vfmv" :
        code = fflags_wrapper(code)

    iop = InstObjParams(name,
        Name,
        'VectorNonSplitInst',
        {'code': code,
         'vm_decl_rd': vm_decl_rd,
         'set_vm_idx': set_vm_idx},
        flags)


    if inst_name == "vfmv" :
        execute_block = VectorFloatNonSplitExecute.subst(iop)
        decode_block = VectorFloatDecodeBlock.subst(iop)
    elif inst_name == "vmv" :
        execute_block = VectorIntNonSplitExecute.subst(iop)
        decode_block = VectorIntDecodeBlock.subst(iop)
    else :
        error("Unsupported inst for VectorNonSplitFormat: %s" % inst_name)

    # Because of the use of templates, we had to put all parts in header to
    # keep the compiler happy.
    header_output = \
        VectorNonSplitDeclare.subst(iop) + \
        VectorNonSplitConstructor.subst(iop) + \
        execute_block

}};

def format VectorMaskFormat(code, category, *flags) {{
    inst_name, inst_suffix = name.split("_", maxsplit=1)
    old_vd_idx = 2
    if category not in ["OPMVV"]:
        error("not supported category for VectorIntFormat: %s" % category)
    dest_reg_id = "vecRegClass[_machInst.vd]"
    src1_reg_id = "vecRegClass[_machInst.vs1]"
    src2_reg_id = "vecRegClass[_machInst.vs2]"

    # The tail of vector mask inst should be treated as tail-agnostic.
    # We treat it with tail-undisturbed policy, since
    # the test suits only support undisturbed policy.
    # TODO: remove it
    old_dest_reg_id = "vecRegClass[_machInst.vd]"

    set_src_reg_idx = ""
    set_src_reg_idx += setSrcWrapper(src1_reg_id)
    set_src_reg_idx += setSrcWrapper(src2_reg_id)
    set_src_reg_idx += setSrcWrapper(old_dest_reg_id)

    set_dest_reg_idx = setDestWrapper(dest_reg_id)

    code = loopWrapper(code, micro_inst = False)

    iop = InstObjParams(name,
        Name,
        'VectorNonSplitInst',
        {'code': code,
         'set_dest_reg_idx': set_dest_reg_idx,
         'set_src_reg_idx': set_src_reg_idx,
         'copy_old_vd': copyOldVd(old_vd_idx)},
        flags)
    # Because of the use of templates, we had to put all parts in header to
    # keep the compiler happy.
    header_output = \
        VectorMaskDeclare.subst(iop) + \
        VectorMaskConstructor.subst(iop) + \
        VectorMaskExecute.subst(iop)

    decode_block = VectorMaskDecodeBlock.subst(iop)
}};

def format VectorReduceIntFormat(code, category, *flags) {{
    iop = InstObjParams(name, Name, 'VectorArithMacroInst', {'code': code},
                        flags)
    inst_name, inst_suffix = name.split("_", maxsplit=1)
    dest_reg_id = "vecRegClass[_machInst.vd]"
    src1_reg_id = "vecRegClass[_machInst.vs1]"
    src2_reg_id = "vecRegClass[_machInst.vs2 + _microIdx]"
    old_dest_reg_id = "vecRegClass[_machInst.vd]"
    set_dest_reg_idx = setDestWrapper(dest_reg_id)
    set_src_reg_idx = setSrcWrapper(src1_reg_id)
    set_src_reg_idx += setSrcWrapper(src2_reg_id)
    # Treat tail undisturbed/agnostic as the same
    # We always need old rd as src vreg
    set_src_reg_idx += setSrcWrapper(old_dest_reg_id)
    set_src_reg_idx += setSrcVm()
    vm_decl_rd = vmDeclAndReadData()
    type_def = '''
        using vu [[maybe_unused]] = std::make_unsigned_t<ElemType>;
        using vi [[maybe_unused]] = std::make_signed_t<ElemType>;
    '''
    microiop = InstObjParams(name + "_micro",
        Name + "Micro",
        'VectorArithMicroInst',
        {'code': code,
         'set_dest_reg_idx': set_dest_reg_idx,
         'set_src_reg_idx': set_src_reg_idx,
         'vm_decl_rd': vm_decl_rd,
         'type_def': type_def,
         'copy_old_vd': copyOldVd(2),
         'vi_check_reduction': VI_CHECK_REDUCTION(False)
        },
        flags)

    # Because of the use of templates, we had to put all parts in header to
    # keep the compiler happy.
    header_output = \
        VectorReduceMicroDeclare.subst(microiop) + \
        VectorReduceMicroConstructor.subst(microiop) + \
        VectorReduceIntMicroExecute.subst(microiop) + \
        VectorReduceMacroDeclare.subst(iop) + \
        VectorReduceMacroConstructor.subst(iop)
    decode_block = VectorIntDecodeBlock.subst(iop)
}};

def format VectorReduceFloatFormat(code, category, *flags) {{
    iop = InstObjParams(name, Name, 'VectorArithMacroInst', {'code': code},
                        flags)
    inst_name, inst_suffix = name.split("_", maxsplit=1)
    dest_reg_id = "vecRegClass[_machInst.vd]"
    src1_reg_id = "vecRegClass[_machInst.vs1]"
    src2_reg_id = "vecRegClass[_machInst.vs2 + _microIdx]"
    old_dest_reg_id = "vecRegClass[_machInst.vd]"
    set_dest_reg_idx = setDestWrapper(dest_reg_id)
    set_src_reg_idx = setSrcWrapper(src1_reg_id)
    set_src_reg_idx += setSrcWrapper(src2_reg_id)
    # Treat tail undisturbed/agnostic as the same
    # We always need old rd as src vreg
    set_src_reg_idx += setSrcWrapper(old_dest_reg_id)
    set_src_reg_idx += setSrcVm()
    vm_decl_rd = vmDeclAndReadData()
    type_def = '''
        using et = ElemType;
        using vu = decltype(et::v);
    '''

    code = fflags_wrapper(code)

    microiop = InstObjParams(name + "_micro",
        Name + "Micro",
        'VectorArithMicroInst',
        {'code': code,
         'set_dest_reg_idx': set_dest_reg_idx,
         'set_src_reg_idx': set_src_reg_idx,
         'vm_decl_rd': vm_decl_rd,
         'type_def': type_def,
         'copy_old_vd': copyOldVd(2),
         'vi_check_reduction': VI_CHECK_REDUCTION(False)
        },
        flags)

    # Because of the use of templates, we had to put all parts in header to
    # keep the compiler happy.
    header_output = \
        VectorReduceMicroDeclare.subst(microiop) + \
        VectorReduceMicroConstructor.subst(microiop) + \
        VectorReduceFloatMicroExecute.subst(microiop) + \
        VectorReduceMacroDeclare.subst(iop) + \
        VectorReduceMacroConstructor.subst(iop)
    decode_block = VectorFloatDecodeBlock.subst(iop)
}};

def format VectorReduceFloatWideningFormat(code, category, *flags) {{
    iop = InstObjParams(name, Name, 'VectorArithMacroInst', {'code': code},
                        flags)
    inst_name, inst_suffix = name.split("_", maxsplit=1)
    dest_reg_id = "vecRegClass[_machInst.vd]"
    src1_reg_id = "vecRegClass[_machInst.vs1]"
    src2_reg_id = "vecRegClass[_machInst.vs2 + _microIdx]"
    old_dest_reg_id = "vecRegClass[_machInst.vd]"
    set_dest_reg_idx = setDestWrapper(dest_reg_id)
    set_src_reg_idx = setSrcWrapper(src1_reg_id)
    set_src_reg_idx += setSrcWrapper(src2_reg_id)
    # Treat tail undisturbed/agnostic as the same
    # We always need old rd as src vreg
    set_src_reg_idx += setSrcWrapper(old_dest_reg_id)
    set_src_reg_idx += setSrcVm()
    vm_decl_rd = vmDeclAndReadData()
    type_def = '''
        using et = ElemType;
        using vu [[maybe_unused]] = decltype(et::v);
        using ewt = typename double_width<et>::type;
        using vwu = decltype(ewt::v);
    '''
    microiop = InstObjParams(name + "_micro",
        Name + "Micro",
        'VectorArithMicroInst',
        {'code': code,
         'set_dest_reg_idx': set_dest_reg_idx,
         'set_src_reg_idx': set_src_reg_idx,
         'vm_decl_rd': vm_decl_rd,
         'type_def': type_def,
         'copy_old_vd': copyOldVd(2),
         'vi_check_reduction': VI_CHECK_REDUCTION(True)
        },
        flags)

    # Because of the use of templates, we had to put all parts in header to
    # keep the compiler happy.
    header_output = \
        VectorReduceMicroDeclare.subst(microiop) + \
        VectorReduceMicroConstructor.subst(microiop) + \
        VectorReduceFloatWideningMicroExecute.subst(microiop) + \
        VectorReduceMacroDeclare.subst(iop) + \
        VectorReduceMacroConstructor.subst(iop)
    decode_block = VectorFloatWideningDecodeBlock.subst(iop)
}};

def format VectorIntVxsatFormat(code, category, *flags) {{
    iop = InstObjParams(name, Name, 'VectorArithMacroInst', {'code': code},
                        flags)
    inst_name, inst_suffix = name.split("_", maxsplit=1)
    vi_check_sss_flag = True
    old_vd_idx = 2
    dest_reg_id = "vecRegClass[_machInst.vd + _microIdx]"
    src1_reg_id = ""
    if category in ["OPIVV"]:
        src1_reg_id = "vecRegClass[_machInst.vs1 + _microIdx]"
    elif category in ["OPIVX"]:
        src1_reg_id = "intRegClass[_machInst.rs1]"
        vi_check_sss_flag = False
    elif category == "OPIVI":
        old_vd_idx = 1
        vi_check_sss_flag = False
    else:
        error("not supported category for VectorIntVxsatFormat: %s" % category)
    src2_reg_id = "vecRegClass[_machInst.vs2 + _microIdx]"
    src3_reg_id = "vecRegClass[_machInst.vs3 + _microIdx]"
    set_dest_reg_idx = setDestWrapper(dest_reg_id)

    set_src_reg_idx = ""
    if category != "OPIVI":
        set_src_reg_idx += setSrcWrapper(src1_reg_id)
    set_src_reg_idx += setSrcWrapper(src2_reg_id)
    set_src_reg_idx += setSrcWrapper(src3_reg_id)
    set_src_reg_idx += setSrcVm()
    vm_decl_rd = vmDeclAndReadData()
    vi_check_sss = VI_CHECK_SSS(vi_check_sss_flag)

    code = maskCondWrapper(code)
    code = eiDeclarePrefix(code)
    code = loopWrapper(code)

    microiop = InstObjParams(name + "_micro",
        Name + "Micro",
        'VectorArithMicroInst',
        {'code': code,
         'set_dest_reg_idx': set_dest_reg_idx,
         'set_src_reg_idx': set_src_reg_idx,
         'vm_decl_rd': vm_decl_rd,
         'copy_old_vd': copyOldVd(old_vd_idx),
         'vi_check_sss': vi_check_sss
        },
        flags)

    # Because of the use of templates, we had to put all parts in header to
    # keep the compiler happy.
    header_output = \
        VectorIntVxsatMicroDeclare.subst(microiop) + \
        VectorIntVxsatMicroConstructor.subst(microiop) + \
        VectorIntMicroExecute.subst(microiop) + \
        VectorIntVxsatMacroDeclare.subst(iop) + \
        VectorIntVxsatMacroConstructor.subst(iop)

    decode_block = VectorIntDecodeBlock.subst(iop)
}};

def format VectorReduceIntWideningFormat(code, category, *flags) {{
    iop = InstObjParams(name, Name, 'VectorArithMacroInst', {'code': code},
                        flags)
    inst_name, inst_suffix = name.split("_", maxsplit=1)
    dest_reg_id = "vecRegClass[_machInst.vd]"
    src1_reg_id = "vecRegClass[_machInst.vs1]"
    src2_reg_id = "vecRegClass[_machInst.vs2 + _microIdx]"
    old_dest_reg_id = "vecRegClass[_machInst.vd]"
    set_dest_reg_idx = setDestWrapper(dest_reg_id)
    set_src_reg_idx = setSrcWrapper(src1_reg_id)
    set_src_reg_idx += setSrcWrapper(src2_reg_id)
    # Treat tail undisturbed/agnostic as the same
    # We always need old rd as src vreg
    set_src_reg_idx += setSrcWrapper(old_dest_reg_id)
    set_src_reg_idx += setSrcVm()
    vm_decl_rd = vmDeclAndReadData()
    microiop = InstObjParams(name + "_micro",
        Name + "Micro",
        'VectorArithMicroInst',
        {'code': code,
         'set_dest_reg_idx': set_dest_reg_idx,
         'set_src_reg_idx': set_src_reg_idx,
         'vm_decl_rd': vm_decl_rd,
         'copy_old_vd': copyOldVd(2),
         'vi_check_reduction': VI_CHECK_REDUCTION(True)
        },
        flags)

    # Because of the use of templates, we had to put all parts in header to
    # keep the compiler happy.
    header_output = \
        VectorReduceMicroDeclare.subst(microiop) + \
        VectorReduceMicroConstructor.subst(microiop) + \
        VectorReduceIntWideningMicroExecute.subst(microiop) + \
        VectorReduceMacroDeclare.subst(iop) + \
        VectorReduceMacroConstructor.subst(iop)
    decode_block = VectorIntWideningDecodeBlock.subst(iop)
}};

let {{

def VectorSlideBase(name, Name, category, code, flags, macro_construtor,
        decode_template, micro_execute_template):
    macroop_class_name = 'VectorSlideMacroInst'
    microop_class_name = 'VectorSlideMicroInst'
    # Make sure flags are in lists (convert to lists if not).
    flags = makeList(flags)
    iop = InstObjParams(name, Name, macroop_class_name, {'code': code},
                        flags)
    inst_name, inst_suffix = name.split("_", maxsplit=1)
    dest_reg_id = "vecRegClass[_machInst.vd + vdIdx]"
    src2_reg_id = "vecRegClass[_machInst.vs2 + vs2Idx]"
    src1_ireg_id = "intRegClass[_machInst.rs1]"
    src1_freg_id = "floatRegClass[_machInst.rs1]"

    # The tail of vector mask inst should be treated as tail-agnostic.
    # We treat it with tail-undisturbed policy, since
    # the test suits only support undisturbed policy.
    num_src_regs = 0

    old_dest_reg_id = "vecRegClass[_machInst.vd + vdIdx]"
    set_src_reg_idx = ""
    if category in ["OPIVX", "OPMVX"]:
        set_src_reg_idx += setSrcWrapper(src1_ireg_id)
        num_src_regs += 1
    elif category in ["OPFVF"]:
        set_src_reg_idx += setSrcWrapper(src1_freg_id)
        num_src_regs += 1
    set_src_reg_idx += setSrcWrapper(src2_reg_id)
    num_src_regs += 1
    old_vd_idx = num_src_regs
    set_src_reg_idx += setSrcWrapper(old_dest_reg_id)
    set_dest_reg_idx = setDestWrapper(dest_reg_id)
    vm_decl_rd = vmDeclAndReadData()
    set_src_reg_idx += setSrcVm()
    vi_check_slide_flag = inst_name[-2:]=="up"
    microiop = InstObjParams(name + "_micro",
        Name + "Micro",
        microop_class_name,
        {'code': code,
         'set_dest_reg_idx': set_dest_reg_idx,
         'set_src_reg_idx': set_src_reg_idx,
         'vm_decl_rd': vm_decl_rd,
         'copy_old_vd': copyOldVd(old_vd_idx),
         'vi_check_slide':VI_CHECK_SLIDE(vi_check_slide_flag)
        },
        flags)
    # Because of the use of templates, we had to put all parts in header to
    # keep the compiler happy.
    # Because of the use of templates, we had to put all parts in header to
    # keep the compiler happy.
    header_output = \
        VectorSlideMicroDeclare.subst(microiop) + \
        VectorSlideMicroConstructor.subst(microiop) + \
        micro_execute_template.subst(microiop) + \
        VectorSlideMacroDeclare.subst(iop) + \
        macro_construtor.subst(iop)

    decode_block = decode_template.subst(iop)
    return (header_output, decode_block)

}};

def format VectorSlideUpFormat(code, category, *flags) {{
    (header_output, decode_block) = VectorSlideBase(name, Name, category, code,
        flags,
        macro_construtor = VectorSlideUpMacroConstructor,
        decode_template = VectorIntDecodeBlock,
        micro_execute_template = VectorSlideMicroExecute)
}};

def format VectorSlideDownFormat(code, category, *flags) {{
    (header_output, decode_block) = VectorSlideBase(name, Name, category, code,
        flags,
        macro_construtor = VectorSlideDownMacroConstructor,
        decode_template = VectorIntDecodeBlock,
        micro_execute_template = VectorSlideMicroExecute)
}};

def format VectorFloatSlideUpFormat(code, category, *flags) {{
    (header_output, decode_block) = VectorSlideBase(name, Name, category, code,
        flags,
        macro_construtor = VectorSlideUpMacroConstructor,
        decode_template = VectorFloatDecodeBlock,
        micro_execute_template = VectorFloatSlideMicroExecute)
}};

def format VectorFloatSlideDownFormat(code, category, *flags) {{
    (header_output, decode_block) = VectorSlideBase(name, Name, category, code,
        flags,
        macro_construtor = VectorSlideDownMacroConstructor,
        decode_template = VectorFloatDecodeBlock,
        micro_execute_template = VectorFloatSlideMicroExecute)
}};
